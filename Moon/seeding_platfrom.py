import streamlit as st
import pandas as pd
import numpy as np
import os
import re
import json
from openai import OpenAI 
from fpdf import FPDF 
import io 

# --- (V23) CSV/PDF í—¬í¼ í•¨ìˆ˜ë“¤ (ë³€ê²½ ì—†ìŒ) ---
@st.cache_data
def to_csv(df):
    """ë°ì´í„°í”„ë ˆì„ì„ CSV (UTF-8) ë°”ì´íŠ¸ë¡œ ë³€í™˜"""
    return df.to_csv(index=False).encode('utf-8-sig') 

class PDF(FPDF):
    """PDF ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ FPDF í´ë˜ìŠ¤"""
    def header(self):
        self.set_font('MalgunGothic', 'B', 15)
        self.cell(0, 10, 'AI ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ë³´ê³ ì„œ (DRAFT)', 0, 1, 'C')
        self.ln(10)
    def chapter_title(self, title):
        self.set_font('MalgunGothic', 'B', 12)
        self.cell(0, 8, title, 0, 1, 'L')
        self.ln(2)
    def chapter_body(self, body, font_size=10):
        self.set_font('MalgunGothic', '', font_size)
        self.multi_cell(0, 6, body)
        self.ln()
    def add_korean_fonts(self):
        try:
            self.add_font('MalgunGothic', '', 'MALGUN.TTF') 
            self.add_font('MalgunGothic', 'B', 'MALGUNBD.TTF')
        except Exception:
            self.set_font('Arial', 'B', 10) 

@st.cache_data
def generate_pdf_report(df_seeding_list, insight_report_content, brand_fit_result, persona_context, filter_report_content, analysis_report_content, influencer_name):
    pdf = PDF(orientation='P', unit='mm', format='A4')
    pdf.add_korean_fonts()
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.chapter_title(f"ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ìµœì¢… ë¶„ì„ ë³´ê³ ì„œ - {influencer_name}")
    pdf.chapter_title("1. AI í†µí•© ë¶„ì„ ë° ìµœì¢… ì œì–¸")
    pdf.chapter_body(insight_report_content)
    pdf.ln(5)
    pdf.chapter_title("2. ë¸Œëœë“œ í• í‰ê°€ (Soft Fit)")
    if brand_fit_result:
        fit_score = brand_fit_result.get('brand_fit_score', 'N/A')
        fit_reason = brand_fit_result.get('reason', 'ë¶„ì„ ê²°ê³¼ ì—†ìŒ')
        pdf.chapter_body(f"í‰ê°€ ì ìˆ˜: {fit_score} / 100ì ")
        pdf.chapter_body(f"í‰ê°€ ê·¼ê±°: {fit_reason}")
    else:
        pdf.chapter_body("ë¸Œëœë“œ í• ë¶„ì„ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (4.2 ì„¹ì…˜ ì°¸ì¡°)")
    pdf.ln(5)
    pdf.chapter_title("3. ìº í˜ì¸ ëª©í‘œ ë° ë¶„ì„ ë§¥ë½")
    pdf.chapter_body(f"ìº í˜ì¸ í˜ë¥´ì†Œë‚˜: {persona_context[:150]}...")
    pdf.chapter_body(f"1ì°¨ ì°¸ê³  ë³´ê³ ì„œ: {filter_report_content[:150]}...")
    pdf.chapter_body(f"ì¶”ê°€ ì°¸ê³  ë³´ê³ ì„œ: {analysis_report_content[:150]}...")
    pdf.ln(5)
    pdf.chapter_title(f"4. ì²¨ë¶€ íŒŒì¼: ìµœì¢… ì‹œë”© í›„ë³´êµ° ëª©ë¡ ({len(df_seeding_list)}ëª…)")
    pdf.chapter_body(f"ìµœì¢… ì‹œë”© í›„ë³´êµ° ëª©ë¡ íŒŒì¼ì€ CSVë¡œ ë³„ë„ ì²¨ë¶€ë©ë‹ˆë‹¤.", font_size=8)
    return bytes(pdf.output(dest='S')) 


# --- (V23) ê¸€ë¡œë²Œ ìƒìˆ˜ ë° DB ê¸°ì¤€ ì •ì˜ (ë³€ê²½ ì—†ìŒ) ---
ALL_COUNTRIES = ['USA', 'Germany', 'Russia', 'France', 'UK', 'Japan', 'South Korea']
ALL_CITIES = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Berlin', 'Hamburg', 'Munich', 'Cologne', 'Frankfurt', 'Moscow', 'Saint Petersburg', 'Novosibirsk', 'Yekaterinburg', 'Paris', 'London', 'Tokyo', 'Seoul']
ALL_INTERESTS = sorted([
    'Skincare', 'K-Beauty', 'Makeup', 'Fashion', 'Lifestyle', 'Gaming', 'Tech',
    'Fitness', 'Wellness', 'Food', 'Travel', 'Music', 'K-Pop', 'Tiktok', 'Dance',
    'Vegan', 'Eco-friendly', 'Luxury', 'Minimalism', 'Art', 'Photography' 
])
ALL_AGES = ['under_18', '18-24', '25-34', '35-44', '45-54', '55_plus'] 
ALL_GENDERS = ['Female', 'Male', 'Mixed'] 

ALL_PLATFORMS = ['Any', 'Instagram', 'Tiktok', 'YouTube']
ALL_GENDERS_OPTIONS = ['Any', 'Female (80% ì´ìƒ)', 'Male (80% ì´ìƒ)', 'Mixed (50/50)']


# --- (V23) ê°€ìƒ ë°ì´í„° ìƒì„± í•¨ìˆ˜ (Top N ì»¬ëŸ¼ ì¶”ê°€) ---
def create_mock_data(filename="influencers_v23.csv"):
    """
    10,000ê°œì˜ 'ë¹„ìœ¨ ê¸°ë°˜' ê°€ìƒ ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ë¥¼ ìƒì„± (Top N ì»¬ëŸ¼ ì¶”ê°€)
    """
    st.toast("ë¹„ìœ¨ ê¸°ë°˜ ê°€ìƒ ë°ì´í„° íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤... (10,000ê±´)")
    num_rows = 10000
    
    def get_random_dist(options):
        dist = np.random.rand(len(options))
        dist /= dist.sum()
        return {option: round(val, 3) for option, val in zip(options, dist)}

    data = []
    for i in range(num_rows):
        row = {
            'influencer_name': f'influencer_{i}',
            'platform': np.random.choice(['Instagram', 'Tiktok', 'YouTube']),
            'followers': np.random.randint(10000, 1000000),
            'engagement_rate_pct': np.round(np.random.uniform(1.0, 10.0), 1),
            'fake_followers_pct': np.round(np.random.uniform(0.5, 30.0), 1)
        }
        
        # Age/Gender
        age_dist = get_random_dist(ALL_AGES)
        for age_range, val in age_dist.items():
            row[f'age_{age_range}'] = val
        gender_dist = get_random_dist(ALL_GENDERS)
        for gender, val in gender_dist.items():
            row[f'gender_{gender}'] = val
        
        # Country/City/Interests (JSON)
        country_dist_dict = get_random_dist(ALL_COUNTRIES)
        city_dist_dict = get_random_dist(ALL_CITIES)
        interest_dist_dict = get_random_dist(ALL_INTERESTS)
        
        row['audience_country_dist'] = json.dumps(country_dist_dict)
        row['audience_city_dist'] = json.dumps(city_dist_dict)
        row['audience_interest_dist'] = json.dumps(interest_dist_dict)
        
        # [V23] Top N ì»¬ëŸ¼ ì¶”ê°€ (UI ê°€ë…ì„±ìš©)
        row['top_country'] = max(country_dist_dict, key=country_dist_dict.get)
        row['top_city'] = max(city_dist_dict, key=city_dist_dict.get)
        row['top_age_range'] = max(age_dist, key=age_dist.get)
        row['top_gender'] = max(gender_dist, key=gender_dist.get)
        row['top_interest'] = max(interest_dist_dict, key=interest_dist_dict.get)

        # ë¹„ìš© ì§€í‘œ
        row['estimated_cpm'] = np.round(np.random.uniform(5.0, 50.0), 2)
        row['estimated_cpv'] = np.round(np.random.uniform(0.01, 0.50), 2)
        row['estimated_cpe'] = np.round(np.random.uniform(0.10, 2.00), 2)
        
        data.append(row)
    
    df = pd.DataFrame(data)
    df.to_csv(filename, index=False)
    st.toast(f"'{filename}' ìƒì„± ì™„ë£Œ! (10,000ê±´)")


# --- (V23) GPT-4 API í˜¸ì¶œ í•¨ìˆ˜ 1: AI í†µì—­ í•„í„° ì¶”ì¶œìš© (ë…¼ë¦¬ ì˜¤ë¥˜ ìˆ˜ì •) ---
def query_openai_api_for_filters(report_text, model_name="gpt-4-turbo-2024-04-09"): 
    """
    OpenAI GPT-4 APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë³´ê³ ì„œ í…ìŠ¤íŠ¸ë¥¼ 'ì¶”ë¡ 'í•˜ê³  'í†µì—­'í•˜ì—¬ 
    DB í•„í„°ë§ì´ ê°€ëŠ¥í•œ 9ê°€ì§€ ê¸°ì¤€ì˜ JSONì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    
    if "OPENAI_API_KEY" not in st.secrets:
        raise Exception("OpenAI API í‚¤ê°€ secrets.tomlì— ì—†ìŠµë‹ˆë‹¤. (OPENAI_API_KEY)")
    
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    
    valid_countries_str = ", ".join(ALL_COUNTRIES)
    valid_cities_str = ", ".join(ALL_CITIES)
    
    system_prompt = f"""
    You are an expert marketing data analyst. Your task is to analyze the user's report text (in Korean or English), 
    understand the intent, and translate it into a structured JSON object based on the 9 criteria below.

    CRUCIAL: You MUST translate the user's intent (e.g., 'ë¯¸êµ­ ì„œë¶€', 'ì„œìš¸') into the specific, 
    valid database values provided below. Do not output the user's original abstract words.
    DO NOT extract or infer 'Target Interests' or 'Hot Interests'. They are not part of your task.

    --- Valid Database Values (Your 'Answer Sheet') ---
    Valid Countries: [{valid_countries_str}]
    Valid Cities: [{valid_cities_str}]
    Valid Platforms: ["Instagram", "Tiktok", "YouTube"]
    --- End of Valid Values ---

    Rules for Translation and Extraction:
    1.  **Country/City:** Translate user intent into values from the Valid lists only.
    2.  **[V23 LOGIC FIX]** If a specific **Target City** (e.g., 'New York') is extracted, 
        DO NOT extract its parent **Target Country** (e.g., 'USA'). Only extract the most specific location.
        -   User: "ë¯¸êµ­ ë‰´ìš•" -> `Target City: ["New York"]` (O), `Target Country: []` (O)
        -   User: "ë¯¸êµ­" -> `Target City: []` (O), `Target Country: ["USA"]` (O)
        -   User: "ë¯¸êµ­ ì„œë¶€" -> `Target City: ["Los Angeles", "Phoenix"]` (O), `Target Country: []` (O)
    3.  **Age/Platform/Gender:** Extract string values (e.g., "35 to 43", "female", "30s").
    4.  **Followers/Engagement:** Extract numeric concepts (e.g., "50K", "5%").
    5.  **Empty Values:** If not found, use `""` for strings or `[]` for lists.
    6.  **Output:** You MUST respond ONLY with the valid JSON object.

    JSON Format:
    {{
      "Target Age": "", "Target Gender": "", "Target Country": [], "Target City": [], 
      "Target Platform": "", "Min Followers (K)": "", "Max Followers (K)": "",     
      "Min Engagement (%)": "", "Max Fake Followers (%)": ""
    }}
    """
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": report_text}],
            response_format={"type": "json_object"}, 
            temperature=0.0
        )
        
        ai_response_string = response.choices[0].message.content
        filters = json.loads(ai_response_string)
        
        print("--- AI Raw JSON Start (V23 - Filters) ---")
        print(ai_response_string)
        print("--- AI Raw JSON End (V23 - Filters) ---")
        
        return filters

    except Exception as e:
        raise Exception(f"OpenAI (Filter) API í˜¸ì¶œ ì˜¤ë¥˜: {e}")

# --- (V21) GPT-4 API í˜¸ì¶œ í•¨ìˆ˜ 2: Soft Brand Fit (ë³€ê²½ ì—†ìŒ) ---
def query_openai_api_for_brand_fit(brand_keywords_str, audience_interest_dist_json, persona_input, brand_guideline_input, model_name="gpt-4-turbo-2024-04-09"):
    if "OPENAI_API_KEY" not in st.secrets:
        raise Exception("OpenAI API í‚¤ê°€ secrets.tomlì— ì—†ìŠµë‹ˆë‹¤. (OPENAI_API_KEY)")
    
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

    system_prompt = f"""
    You are an expert brand marketer. Your task is to evaluate the semantic relevance (Soft Fit) between a brand's core keywords and an influencer's audience interests, **given our brand persona and the audience's full interest distribution.**
    
    - Brand Persona: The target customer profile.
    - Brand Guidelines: The brand's tone & manner.
    - Brand Core Keywords: These define the brand's identity.
    - Influencer Audience Interests (Distribution): A JSON showing the percentage breakdown of all audience interests.
    
    Your goal is to score this fit from 0 to 100 based on how well the audience's interests align with the brand's identity, **the target persona, and the brand guidelines.**
    
    You MUST respond ONLY with a JSON object in the following format:
    {{
      "brand_fit_score": <score_int>,
      "reason": "<one_sentence_reason_in_Korean_analyzing_the_distribution>"
    }}
    """
    
    user_prompt = f"""
    - **Brand Persona Context:** "{persona_input}"
    - **Brand Guideline Context:** "{brand_guideline_input}"
    - Brand Core Keywords: [{brand_keywords_str}]
    - **Influencer Audience Interest Distribution (JSON):** {audience_interest_dist_json}
    
    Please analyze the semantic relevance **considering ALL context (Persona, Guidelines)**, and provide the Brand Fit score and reason in the specified JSON format.
    """
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            response_format={"type": "json_object"},
            temperature=0.2
        )
        
        ai_response_string = response.choices[0].message.content
        fit_result = json.loads(ai_response_string)
        return fit_result

    except Exception as e:
        raise Exception(f"OpenAI (Brand Fit) API í˜¸ì¶œ ì˜¤ë¥˜: {e}")


# --- (V16) GPT-4 API í˜¸ì¶œ í•¨ìˆ˜ 3: í†µí•© ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ìš© (ë³€ê²½ ì—†ìŒ) ---
def query_openai_api_for_insight(cpm, cpv, cpe, influencer_name, brand_fit_result, 
                                 persona_input, filter_report_content, analysis_report_content, 
                                 benchmark_cpm=15.0, benchmark_cpe=1.0): 
    
    if "OPENAI_API_KEY" not in st.secrets:
        raise Exception("OpenAI API í‚¤ê°€ secrets.tomlì— ì—†ìŠµë‹ˆë‹¤. (OPENAI_API_KEY)")
    
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
    model_name = "gpt-4-turbo-2024-04-09" 

    cpm_insight = "ì €ë ´í•©ë‹ˆë‹¤." if cpm <= benchmark_cpm else "ë‹¤ì†Œ ë¹„ìŒ‰ë‹ˆë‹¤."
    cpe_insight = "ë§¤ìš° íš¨ìœ¨ì ì…ë‹ˆë‹¤." if cpe <= benchmark_cpe else "ë‹¤ì†Œ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤."

    prompt = f"""
    --- Full Context ---
    **1. Our Campaign Goal (Persona):** "{persona_input}"
    **2. External Market Situation (Report File from Step 1):** "{filter_report_content}"
    **3. Additional Data (Report File from Step 3):** "{analysis_report_content}"
    --- End of Context ---

    --- Influencer Data ---
    Influencer: {influencer_name}
    Estimated CPM: ${cpm:.2f} (Market Benchmark: ${benchmark_cpm:.2f})
    Estimated CPV: ${cpv:.2f}
    Estimated CPE: ${cpe:.2f} (Market Benchmark: ${benchmark_cpe:.2f})
    """
    
    if brand_fit_result:
        prompt += f"""
        Brand Fit Score: {brand_fit_result['brand_fit_score']}/100
        Brand Fit Reason: {brand_fit_result['reason']}
        """
    else:
        prompt += "Brand Fit Score: (Not Assessed)\n"
        
    prompt += """
    --- Your Task ---
    Based on **all the context provided above (Goal, Market Reports 1 & 2, and Data)**, write a comprehensive 'Strategic Insight Report' in Korean for a marketing executive.
    
    1.  Start with a clear **Recommendation:** (e.g., "ê³„ì•½ ê°•ë ¥ ì¶”ì²œ.", "ì „ëµì  ì¬ê³  í•„ìš”.").
    2.  Analyze the **Cost Efficiency (CPM/CPE)**.
    3.  Analyze the **Brand Fit** score (if provided) in the context of our **Campaign Goal (Persona)**.
    4.  Incorporate insights from **both report files** (if they are not 'N/A').
    5.  Provide a final, concise justification for your recommendation.
    """
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=400 
        )
        
        insight_report = response.choices[0].message.content
        return insight_report

    except Exception as e:
        raise Exception(f"OpenAI (Insight) API í˜¸ì¶œ ì˜¤ë¥˜: {e}")

# --- (V19) GPT-4 API í˜¸ì¶œ í•¨ìˆ˜ 4: ê³„ì•½ì„œ ì´ˆì•ˆ ìƒì„±ìš© (ë³€ê²½ ì—†ìŒ) ---
def query_openai_api_for_contract(influencer_name, proposed_cost, campaign_period, content_guideline, model_name="gpt-4-turbo-2024-04-09"):
    if "OPENAI_API_KEY" not in st.secrets:
        raise Exception("OpenAI API í‚¤ê°€ secrets.tomlì— ì—†ìŠµë‹ˆë‹¤. (OPENAI_API_KEY)")
    
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

    system_prompt = f"""
    You are an AI legal assistant specializing in marketing contracts. 
    Your task is to draft a clear and professional influencer marketing contract (MOU) in **Korean** suitable for a PDF printout.
    The draft must be based **only** on the 4 variables provided by the user.
    Start with the title: 'ì¸í”Œë£¨ì–¸ì„œ ë§ˆì¼€íŒ… ìº í˜ì¸ ê³„ì•½ì„œ (ì´ˆì•ˆ)'.
    Use clear section headers (e.g., 'ì œ 1ì¡° ê³„ì•½ ë‹¹ì‚¬ì', 'ì œ 2ì¡° ê³„ì•½ ê°œìš”').
    """
    
    user_prompt = f"""
    Draft a professional contract (MOU) in **Korean** using the following details:

    1.  **Influencer (ì„):** {influencer_name}
    2.  **Brand (ê°‘):** d'Alba
    3.  **Proposed Cost (ì§€ê¸‰ ë¹„ìš©):** {proposed_cost}
    4.  **Campaign Period (ê³„ì•½ ê¸°ê°„):** {campaign_period}
    5.  **Content Guidelines (ì£¼ìš” ì½˜í…ì¸  ê°€ì´ë“œë¼ì¸):**
        {content_guideline}
    
    Please structure the output clearly.
    """
    
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            temperature=0.3, 
            max_tokens=1000 
        )
        
        contract_draft = response.choices[0].message.content
        return contract_draft

    except Exception as e:
        raise Exception(f"OpenAI (Contract) API í˜¸ì¶œ ì˜¤ë¥˜: {e}")


# --- (V22) 'ë²ˆì—­' í—¬í¼ í•¨ìˆ˜ë“¤ (ë³€ê²½ ì—†ìŒ) ---
def translate_age_to_cols(ai_age_str):
    if not ai_age_str: return []
    if isinstance(ai_age_str, list): ai_age_str = str(ai_age_str[0]) if ai_age_str else ""
    if not ai_age_str: return []
    
    target_cols = []
    age_lower = str(ai_age_str).lower()
    
    match = re.search(r'(\d+)\s*(-|to)\s*(\d+)', age_lower)
    if match:
        min_age = int(match.group(1)); max_age = int(match.group(3))
        if min_age <= 17: target_cols.append('age_under_18')
        if min_age <= 24 and max_age >= 18: target_cols.append('age_18-24')
        if min_age <= 34 and max_age >= 25: target_cols.append('age_25-34')
        if min_age <= 44 and max_age >= 35: target_cols.append('age_35-44')
        if min_age <= 54 and max_age >= 45: target_cols.append('age_45-54')
        if max_age >= 55: target_cols.append('age_55_plus')
        
    if "30ëŒ€" in age_lower or "30s" in age_lower: target_cols.extend(['age_25-34', 'age_35-44'])
    if "20ëŒ€" in age_lower or "20s" in age_lower: target_cols.extend(['age_18-24', 'age_25-34'])
    if "40ëŒ€" in age_lower or "40s" in age_lower: target_cols.extend(['age_35-44', 'age_45-54'])
        
    return list(set(target_cols)) 


def translate_gender_to_cols(ai_gender_str):
    if not ai_gender_str: return []
    if isinstance(ai_gender_str, list): ai_gender_str = str(ai_gender_str[0]) if ai_gender_str else ""
    if not ai_gender_str: return []

    gender_lower = str(ai_gender_str).lower()
    if "female" in gender_lower or "ì—¬ì„±" in gender_lower or "ì—¬ì" in gender_lower or "women" in gender_lower: return ['gender_Female']
    elif "male" in gender_lower or "ë‚¨ì„±" in gender_lower or "ë‚¨ì" in gender_lower or "men" in gender_lower: return ['gender_Male']
    elif "mixed" in gender_lower or "í˜¼í•©" in gender_lower: return ['gender_Mixed']
    return []

def translate_platform_to_val(ai_platform_str):
    if not ai_platform_str: return 'Any'
    if isinstance(ai_platform_str, list): ai_platform_str = ai_platform_str[0] if ai_platform_str else ""
    if not ai_platform_str: return 'Any'
    
    platform_lower = str(ai_platform_str).lower()
    if "instagram" in platform_lower: return 'Instagram'
    elif "tiktok" in platform_lower or "í‹±í†¡" in platform_lower: return 'Tiktok'
    elif "youtube" in platform_lower or "ìœ íŠœë¸Œ" in platform_lower: return 'YouTube'
    return 'Any'
    

def to_float(value, default=0.0):
    if value is None: return default
    if isinstance(value, list): value = value[0] if value else None
    if value is None: return default
    try:
        clean_value = str(value).lower().replace('%', '').replace('k', '').strip() 
        return float(clean_value)
    except (ValueError, TypeError):
        return default


# --- (V21) AI ì‘ë‹µ 'ë²ˆì—­' ì½œë°± í•¨ìˆ˜ (ë¹„ìœ¨ ê¸°ë°˜ í•„í„°ë§ ë¡œì§) ---
def apply_filters_from_report():
    """íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ë¥¼ ì·¨í•©, AI í˜¸ì¶œ, ê²°ê³¼ë¥¼ 'ë²ˆì—­'í•˜ì—¬ session_stateì— ì €ì¥í•©ë‹ˆë‹¤."""
    
    combined_text = ""
    if st.session_state.persona_input:
        combined_text += "## Campaign Persona ##\n" + st.session_state.persona_input + "\n"
    
    if st.session_state.filter_report_file is not None:
        combined_text += "## Market Report File Content ##\n" + st.session_state.filter_report_file.getvalue().decode("utf-8") + "\n"
        
    if st.session_state.other_requirements_input:
        combined_text += "## Other Requirements ##\n" + st.session_state.other_requirements_input + "\n"

    if not combined_text.strip():
        st.session_state.filter_error_message = "1. íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„ ë˜ëŠ” 2. ê¸°íƒ€ ìš”êµ¬ì‚¬í•­ ì¤‘ í•˜ë‚˜ ì´ìƒì„ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤."
        return

    st.session_state.brand_fit_result = None
    
    try:
        model_name = "gpt-4-turbo-2024-04-09" 
        with st.spinner(f"OpenAI GPT-4 ({model_name})ê°€ ë³´ê³ ì„œë¥¼ ë¶„ì„ ë° í†µì—­ ì¤‘ì…ë‹ˆë‹¤..."):
            filters = query_openai_api_for_filters(combined_text, model_name) 
        
        if not filters:
            st.session_state.filter_error_message = "AIê°€ ë³´ê³ ì„œì—ì„œ ìœ íš¨í•œ í•„í„° í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            return

        st.session_state.target_countries = filters.get("Target Country")
        st.session_state.target_cities = filters.get("Target City")
        st.session_state.target_age_cols = translate_age_to_cols(filters.get("Target Age")) 
        st.session_state.target_gender_cols = translate_gender_to_cols(filters.get("Target Gender"))
        st.session_state.platform = translate_platform_to_val(filters.get('Target Platform'))
        st.session_state.min_followers = to_float(filters.get('Min Followers (K)')) * 1000
        st.session_state.max_followers = to_float(filters.get('Max Followers (K)'), 1000.0) * 1000 
        st.session_state.min_engagement = to_float(filters.get("Min Engagement (%)"), 0.0)
        st.session_state.max_fake_followers = to_float(filters.get("Max Fake Followers (%)"), 30.0)
        
        st.session_state.filter_applied_success = True
        st.session_state.filter_result_json = filters 
        
    except Exception as e:
        st.session_state.filter_error_message = f"AI ì²˜ë¦¬ ì˜¤ë¥˜ ë°œìƒ: {e}"


# --- (V23) ë©”ì¸ ì•± ì‹¤í–‰ í•¨ìˆ˜ (UX/UI ê°œì„ ) ---
def run_app(df):
    
    st.title("d'Alba AI Seeding Platform (V23 - UX/UI ì™„ì„±)")

    # --- (V23) ì‚¬ì´ë“œë°” í•„í„° (ë„ì›€ë§ ì¶”ê°€) ---
    st.sidebar.header("Seeding Criteria (AI ìë™ ì…ë ¥ ë° ìˆ˜ë™ ì¡°ì‘)")
    
    st.sidebar.multiselect("Target Country (êµ­ê°€)", ALL_COUNTRIES, key='target_countries')
    st.sidebar.multiselect("Target City (ë„ì‹œ)", ALL_CITIES, key='target_cities')
    
    age_cols = [f'age_{age}' for age in ALL_AGES] 
    st.sidebar.multiselect("Target Age (ì—°ë ¹)", age_cols, key='target_age_cols')
    
    gender_cols = [f'gender_{g}' for g in ALL_GENDERS]
    st.sidebar.multiselect("Target Gender (ì„±ë³„)", gender_cols, key='target_gender_cols')
    
    st.sidebar.radio("Target Platform", ALL_PLATFORMS, key='platform') 
    st.sidebar.number_input("Min Followers (K)", min_value=0, step=1000, key='min_followers') 
    st.sidebar.number_input("Max Followers (K)", min_value=0, step=1000, key='max_followers')
    
    # [V23] ë„ì›€ë§(help) ì¶”ê°€
    st.sidebar.slider("Min Engagement (%)", 0.0, 10.0, key='min_engagement', step=0.1,
                      help="**ìµœì†Œ ì°¸ì—¬ìœ¨ (í’ˆì§ˆ ë³´ì¦):** ì´ ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ 'ì§„ì„± íŒ¬'ì´ ë§ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. (ê¶Œì¥: 2.5% ì´ìƒ)")
    st.sidebar.slider("Max Fake Followers (%)", 0.0, 30.0, key='max_fake_followers', step=0.5,
                      help="**ìµœëŒ€ ê°€ì§œ íŒ”ë¡œì›Œ (ìœ„í—˜ íšŒí”¼):** ì´ ë¹„ìœ¨ì´ ë†’ì„ìˆ˜ë¡ 'ë¶€ì‹¤ ìì‚°(ë´‡)'ì´ ë§ìŒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. (ê¶Œì¥: 15% ì´í•˜)")

    st.sidebar.slider("ìµœì†Œ íƒ€ê²Ÿ ì¼ì¹˜ ë¹„ìœ¨ (%)", 0, 100, 30, key='target_threshold_pct',
                      help="AI í•„í„°ë§ ì‹œ, ì´ ë¹„ìœ¨(%) ì´ìƒì„ ì°¨ì§€í•˜ëŠ” ì˜¤ë””ì–¸ìŠ¤ë§Œ ê²€ìƒ‰í•©ë‹ˆë‹¤. (ê¸°ë³¸ê°’ 30%)")


    # --- (V22) 1. AI ìº í˜ì¸ ê¸°íš ë° í•„í„°ë§ ---
    st.subheader("1. AI ìº í˜ì¸ ê¸°íš ë° í•„í„°ë§")
    
    st.text_area("1.1 íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„ (í˜ë¥´ì†Œë‚˜)", key='persona_input', 
                 placeholder="[ìš°ë¦¬ê°€ ëˆ„êµ¬ì—ê²Œ íŒ” ê²ƒì¸ê°€?] \nì˜ˆ: ë¯¸êµ­ ë™ë¶€ì— ê±°ì£¼í•˜ëŠ” 30ëŒ€ ì—¬ì„±, ëŸ­ì…”ë¦¬ ìŠ¤í‚¨ì¼€ì–´ì— ê´€ì‹¬ì´ ë§ìŒ...")
    
    st.text_area("1.2 ê¸°íƒ€ ìš”êµ¬ì‚¬í•­ (AI í•„í„°ë§ìš©)", key='other_requirements_input', 
                 placeholder="[ê¸°ìˆ ì ì¸ í•„í„° ì¡°ê±´ì€?] \nì˜ˆ: í‹±í†¡ì»¤ë§Œ, ìµœì†Œ íŒ”ë¡œì›Œ 50K, ìµœëŒ€ 300K, ì°¸ì—¬ìœ¨ 5% ì´ìƒ")

    st.file_uploader("1.3 ì°¸ê³  ë³´ê³ ì„œ íŒŒì¼ (ì„ íƒ ì‚¬í•­)", type="txt", key='filter_report_file') 
    
    st.button("AI ë³´ê³ ì„œë¡œ ìë™ í•„í„°ë§ ì ìš©", 
              on_click=apply_filters_from_report, 
              type="primary", 
              use_container_width=True)
    
    if 'filter_applied_success' in st.session_state and st.session_state.filter_applied_success:
        st.success("AIê°€ ë³´ê³ ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ì´ë“œë°”ì˜ Criteriaë¥¼ ìë™ ì ìš©í–ˆìŠµë‹ˆë‹¤! (ìˆ˜ì • ê°€ëŠ¥)")
        with st.expander("AIê°€ ì¶”ì¶œí•œ ì›ë³¸ JSON ë³´ê¸° (ë””ë²„ê¹…ìš©)"):
            st.json(st.session_state.get('filter_result_json', {}))
        st.session_state.filter_applied_success = False 
            
    if 'filter_error_message' in st.session_state and st.session_state.filter_error_message:
        st.error(st.session_state.filter_error_message)
        st.session_state.filter_error_message = None 

    st.divider()

    # --- (V23) 2. í•„í„°ë§ëœ ì¸í”Œë£¨ì–¸ì„œ ëª©ë¡ (UX/UI ê°œì„ ) ---
    st.subheader("2. í•„í„°ë§ëœ ì¸í”Œë£¨ì–¸ì„œ ëª©ë¡ ('Like' í•˜ë ¤ë©´ âœ… Select)")

    filtered_df = df.copy()
    
    threshold = st.session_state.target_threshold_pct / 100.0
    
    # [í•„í„°ë§ ë¡œì§]
    if st.session_state.target_age_cols:
        filtered_df = filtered_df[filtered_df[st.session_state.target_age_cols].sum(axis=1) >= threshold]
    if st.session_state.target_gender_cols:
        filtered_df = filtered_df[filtered_df[st.session_state.target_gender_cols].sum(axis=1) >= threshold]
    if st.session_state.target_countries:
        def check_dist(dist_dict, keys, threshold):
            total = sum(dist_dict.get(key, 0) for key in keys)
            return total >= threshold
            
        filtered_df = filtered_df[st.session_state.country_dist_loaded.apply(
            check_dist, args=(st.session_state.target_countries, threshold)
        )]
    if st.session_state.target_cities and not filtered_df.empty:
        filtered_df = filtered_df[st.session_state.city_dist_loaded.loc[filtered_df.index].apply(
            check_dist, args=(st.session_state.target_cities, threshold)
        )]
    if st.session_state.platform != 'Any':
        filtered_df = filtered_df[filtered_df['platform'] == st.session_state.platform]
    filtered_df = filtered_df[
        (filtered_df['followers'] >= st.session_state.min_followers) &
        (filtered_df['followers'] <= st.session_state.max_followers) 
    ]
    filtered_df = filtered_df[
        (filtered_df['engagement_rate_pct'] >= st.session_state.min_engagement) &
        (filtered_df['fake_followers_pct'] <= st.session_state.max_fake_followers)
    ]

    st.info(f"ì´ {len(df)}ëª…ì˜ ì¸í”Œë£¨ì–¸ì„œ ì¤‘ {len(filtered_df)}ëª…ì´ í•„í„°ë§ë˜ì—ˆìŠµë‹ˆë‹¤. (ê¸°ì¤€ ë¹„ìœ¨: {st.session_state.target_threshold_pct}%)")

    if not filtered_df.empty:
        # [V23] 'Like All' / 'Unlike All' ë²„íŠ¼
        col1_all, col2_all = st.columns(2)
        if col1_all.button("âœ… Like All (ì „ì²´ ì„ íƒ)", use_container_width=True):
            st.session_state.liked_influencers.update(filtered_df['influencer_name'])
            st.rerun() 
        if col2_all.button("âŒ Unlike All (ì „ì²´ í•´ì œ)", use_container_width=True):
            st.session_state.liked_influencers.difference_update(filtered_df['influencer_name'])
            st.rerun() 

        filtered_df['âœ… Select'] = filtered_df['influencer_name'].apply(
            lambda x: x in st.session_state.liked_influencers
        )
        
        # [V23] UI ì •ë¦¬: top_ ì»¬ëŸ¼ë§Œ ë…¸ì¶œ
        cols_to_display = ['âœ… Select', 'influencer_name', 'platform', 'followers', 'engagement_rate_pct', 
                           'fake_followers_pct', 'top_country', 'top_city', 'top_age_range', 'top_gender', 'top_interest']
        
        edited_df = st.data_editor(
            filtered_df[cols_to_display],
            key='selection_editor',
            disabled=[col for col in cols_to_display if col != 'âœ… Select']
        )
        
        # [V23.1] ë¬´í•œ ë£¨í”„ ìˆ˜ì • (Rerun ë¡œì§ ê°„ì†Œí™”)
        current_view_names = set(filtered_df['influencer_name'])
        edited_likes = set(edited_df[edited_df['âœ… Select'] == True]['influencer_name'])
        
        unliked_in_view = current_view_names - edited_likes
        st.session_state.liked_influencers.difference_update(unliked_in_view)
        st.session_state.liked_influencers.update(edited_likes)
        
    else:
        st.dataframe(filtered_df) 

    st.divider()

    # --- (V23) 3, 4, 5ë‹¨ê³„ í†µí•© íƒ­ êµ¬ì¡° ---
    liked_names_list = list(st.session_state.liked_influencers)
    
    if not liked_names_list:
        st.warning("ë¨¼ì € '2. í•„í„°ë§ëœ ì¸í”Œë£¨ì–¸ì„œ ëª©ë¡'ì—ì„œ 'âœ… Select'ë¡œ ë¶„ì„í•  ì¸í”Œë£¨ì–¸ì„œë¥¼ 1ëª… ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return

    # [V23] íƒ­ ë°–(ìƒë‹¨)ìœ¼ë¡œ Selectbox ì´ë™
    selected_influencer_name = st.selectbox(
        "ë¶„ì„í•  'Like' ì¸í”Œë£¨ì–¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”:", 
        options=liked_names_list,
        key="analysis_selector_master",
        help="ì—¬ê¸°ì„œ ì„ íƒí•˜ë©´ 3, 4, 5ë²ˆ íƒ­ì˜ ë‚´ìš©ì´ ëª¨ë‘ ì—°ë™ë©ë‹ˆë‹¤."
    )

    if not selected_influencer_name:
        st.info("ë¶„ì„í•  ì¸í”Œë£¨ì–¸ì„œë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return
        
    influencer_data = df[df['influencer_name'] == selected_influencer_name].iloc[0]

    tab_efficiency, tab_analysis, tab_contract = st.tabs([
        "ğŸ’° 3. ìƒì„¸ ë¶„ì„ & ë¹„ìš© í™•ì¸",
        "ğŸ’ 4. AI ì‹¬ì¸µ ë¶„ì„ & ë³´ê³ ",
        "âœï¸ 5. ìµœì¢… ê³„ì•½ ë° ê²°ì¬"
    ])


    # =========================================================================
    # ğŸ’° íƒ­ 3. ìƒì„¸ ë¶„ì„ ë° ë¹„ìš© í™•ì¸
    # =========================================================================
    with tab_efficiency:
        st.subheader(f"3.1 {selected_influencer_name} (ê¸°ë³¸ ì •ë³´)")

        cpm = influencer_data['estimated_cpm']
        cpv = influencer_data['estimated_cpv']
        cpe = influencer_data['estimated_cpe']
        
        st.markdown("#### ë¹„ìš© ì§€í‘œ (Estimated)")
        col1, col2, col3 = st.columns(3)
        col1.metric("Estimated CPM", f"${cpm:.2f}")
        col2.metric("Estimated CPV", f"${cpv:.2f}")
        col3.metric("Estimated CPE", f"${cpe:.2f}")
        
        st.markdown("---")

        # [V23] ìƒì„¸ ë¶„í¬ (ì‹œê°í™”)
        st.markdown("#### ğŸ“ˆ ì˜¤ë””ì–¸ìŠ¤ ìƒì„¸ ë¶„í¬ (Raw Data)")
        
        with st.expander("í´ë¦­í•˜ì—¬ ëª¨ë“  ì˜¤ë””ì–¸ìŠ¤ ë¹„ìœ¨ ì°¨íŠ¸ í™•ì¸"):
            
            # [V23] Age/Gender (Bar Chart)
            st.markdown("##### ğŸ‚ ì—°ë ¹ ë° ì„±ë³„ ë¶„í¬ (Top 5)")
            age_data = {col.split('_')[1]: influencer_data[col] for col in df.columns if col.startswith('age_')}
            gender_data = {col.split('_')[1]: influencer_data[col] for col in df.columns if col.startswith('gender_')}
            
            df_age = pd.DataFrame.from_dict(age_data, orient='index', columns=['Percentage']).nlargest(5, 'Percentage')
            df_gender = pd.DataFrame.from_dict(gender_data, orient='index', columns=['Percentage']).nlargest(5, 'Percentage')
            
            st.bar_chart(df_age)
            st.bar_chart(df_gender)

            st.markdown("##### ğŸŒ êµ­ê°€ ë° ë„ì‹œ ë¶„í¬ (Top 5)")
            country_dist = json.loads(influencer_data['audience_country_dist'])
            city_dist = json.loads(influencer_data['audience_city_dist'])
            
            df_country = pd.DataFrame.from_dict(country_dist, orient='index', columns=['Percentage']).nlargest(5, 'Percentage')
            df_city = pd.DataFrame.from_dict(city_dist, orient='index', columns=['Percentage']).nlargest(5, 'Percentage')

            st.bar_chart(df_country)
            st.bar_chart(df_city)

            st.markdown("##### ğŸ¨ ê´€ì‹¬ì‚¬ ë¶„í¬ (Top 5)")
            interest_dist = json.loads(influencer_data['audience_interest_dist'])
            df_interest = pd.DataFrame.from_dict(interest_dist, orient='index', columns=['Percentage']).nlargest(5, 'Percentage')
            st.bar_chart(df_interest)
            
        # [V23] Unlike ë²„íŠ¼
        st.markdown("---")
        def unlike_selected_influencer_3():
            st.session_state.liked_influencers.discard(selected_influencer_name)
            st.session_state.brand_fit_result = None
            st.rerun() 
        
        st.button(f"ğŸ’” **{selected_influencer_name}**ì„(ë¥¼) 'Like' ëª©ë¡ì—ì„œ ì œê±° (Unlike)", 
                  type="secondary", 
                  use_container_width=True,
                  on_click=unlike_selected_influencer_3,
                  key="unlike_button_3")

    # =========================================================================
    # ğŸ’ íƒ­ 4. AI ì‹¬ì¸µ ë¶„ì„ & ë³´ê³ 
    # =========================================================================
    with tab_analysis:
        st.subheader(f"4.1 {selected_influencer_name} (AI ì‹¬ì¸µ ë¶„ì„)")
        
        persona_context = st.session_state.persona_input
        
        st.markdown("#### 4.2 ë¶„ì„ ë§¥ë½ ì œê³µ")
        if persona_context:
            st.info(f"**ì ìš©ëœ í˜ë¥´ì†Œë‚˜ (1ë‹¨ê³„ ìë™ ë¡œë“œ):**\n\n {persona_context}")
        else:
            st.error("ê²½ê³ : '1.1 íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„'ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. AI ë¶„ì„ í€„ë¦¬í‹°ê°€ ë‚®ì•„ì§‘ë‹ˆë‹¤.")

        st.multiselect(
            "A. ë¸Œëœë“œ í•µì‹¬ í‚¤ì›Œë“œ (Soft Fit í‰ê°€ìš©)", 
            options=ALL_INTERESTS, 
            key='brand_keywords_input_4',
            help="d'Alba ë¸Œëœë“œì™€ ê°€ì¥ ì—°ê´€ì„±ì´ ë†’ë‹¤ê³  ìƒê°í•˜ëŠ” í‚¤ì›Œë“œë¥¼ ëª¨ë‘ ì„ íƒí•˜ì„¸ìš”."
        )
        st.text_area("B. ë¸Œëœë“œ ê°€ì´ë“œë¼ì¸ (ì„ íƒ ì‚¬í•­)", key='analysis_brand_guideline_input', 
                     placeholder="ì˜ˆ: d'AlbaëŠ” 'ìš°ì•„í•¨', 'ì´íƒˆë¦¬ì•„', 'ë¹„ê±´'ì„ ì¤‘ìš”ì‹œí•˜ëŠ” ëŸ­ì…”ë¦¬ í†¤ì•¤ë§¤ë„ˆë¥¼ ê°€ì§‘ë‹ˆë‹¤.")
        
        st.file_uploader("C. ì¶”ê°€ ì°¸ê³  ë³´ê³ ì„œ (ë‚´ë¶€ ì„±ê³¼/ê²½ìŸì‚¬ ìë£Œ)", type="txt", key='analysis_report_file') 

        brand_keywords_list = st.session_state.brand_keywords_input_4 
        if st.button("GPT-4ë¡œ ë¸Œëœë“œ í• í‰ê°€", key="fit_button_4", use_container_width=False):
            if not brand_keywords_list: st.error("ë¸Œëœë“œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
            elif not persona_context: st.error("ë¸Œëœë“œ í•ì„ í‰ê°€í•˜ë ¤ë©´ '1.1 íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„'ì„ ë¨¼ì € ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("GPT-4ê°€ ì í•©ë„ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        brand_keywords_str_for_api = ", ".join(brand_keywords_list) 
                        
                        fit_result = query_openai_api_for_brand_fit(
                            brand_keywords_str_for_api, 
                            influencer_data['audience_interest_dist'],
                            st.session_state.persona_input, 
                            st.session_state.analysis_brand_guideline_input 
                        )
                        st.session_state.brand_fit_result = (selected_influencer_name, fit_result)
                    except Exception as e:
                        st.error(f"ë¸Œëœë“œ í• ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        if st.session_state.brand_fit_result and st.session_state.brand_fit_result[0] == selected_influencer_name:
            fit_data = st.session_state.brand_fit_result[1]
            st.markdown("#### AI Brand Fit Score")
            st.metric("ì ìˆ˜", f"{fit_data['brand_fit_score']} / 100")
            st.info(f"**AI ë¶„ì„:** {fit_data['reason']}")
        else:
             st.warning("ë¨¼ì € 'GPT-4ë¡œ ë¸Œëœë“œ í• í‰ê°€' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

        st.markdown("---")
        
        st.markdown("#### 4.3 í†µí•© ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸")
        if st.button("GPT-4ë¡œ í†µí•© ì¸ì‚¬ì´íŠ¸ ë³´ê³ ì„œ ìƒì„±", type="primary", use_container_width=True):
            if not persona_context: 
                st.error("í†µí•© ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ë ¤ë©´ '1.1 íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„'ì„ ë°˜ë“œì‹œ ì…ë ¥í•´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                with st.spinner("GPT-4ê°€ ëª¨ë“  ë§¥ë½ì„ í†µí•© ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        benchmark_cpm = 15.0 
                        benchmark_cpe = 1.0
                        
                        brand_fit_result_data = st.session_state.brand_fit_result[1] if st.session_state.brand_fit_result and st.session_state.brand_fit_result[0] == selected_influencer_name else None
                        
                        filter_report_content = "N/A (1ì°¨ ë³´ê³ ì„œ ì—†ìŒ)"
                        if st.session_state.filter_report_file is not None:
                            filter_report_content = st.session_state.filter_report_file.getvalue().decode("utf-8")

                        analysis_report_content = "N/A (ì¶”ê°€ ë³´ê³ ì„œ ì—†ìŒ)"
                        if st.session_state.analysis_report_file is not None:
                            analysis_report_content = st.session_state.analysis_report_file.getvalue().decode("utf-8")
                        
                        insight_report = query_openai_api_for_insight(
                            influencer_data['estimated_cpm'], influencer_data['estimated_cpv'], influencer_data['estimated_cpe'], selected_influencer_name,
                            brand_fit_result_data,
                            st.session_state.persona_input, 
                            filter_report_content, 
                            analysis_report_content, 
                            benchmark_cpm, benchmark_cpe
                        )
                        st.session_state.insight_report = (selected_influencer_name, insight_report) 
                        st.markdown("##### ğŸ’¡ GPT-4 ìµœì¢… ë¶„ì„ ë¦¬í¬íŠ¸")
                        st.success(insight_report)
                    except Exception as e:
                        st.error(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        st.markdown("---")
        def unlike_selected_influencer_4():
            st.session_state.liked_influencers.discard(selected_influencer_name)
            st.session_state.brand_fit_result = None
            st.rerun() 
        
        st.button(f"ğŸ’” **{selected_influencer_name}**ì„(ë¥¼) 'Like' ëª©ë¡ì—ì„œ ì œê±° (Unlike)", 
                  type="secondary", 
                  use_container_width=True,
                  on_click=unlike_selected_influencer_4,
                  key="unlike_button_4")


    # =========================================================================
    # âœï¸ íƒ­ 5. ìµœì¢… ê³„ì•½ì„œ ì‘ì„± ë° ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ
    # =========================================================================
    with tab_contract:
        st.subheader("5.1 íŒ€ì¥ ê²°ì¬ ë° ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
        
        seeding_list_df = df[df['influencer_name'].isin(liked_names_list)].copy()
        
        st.info(f"ê²°ì¬ ìš”ì²­í•  ìµœì¢… í›„ë³´ ì¸í”Œë£¨ì–¸ì„œ: {len(seeding_list_df)}ëª…")

        st.markdown("#### A. ìµœì¢… ì‹œë”© ëª©ë¡ (CSV íŒŒì¼)")
        
        available_cols = list(seeding_list_df.columns)
        default_cols = ['influencer_name', 'platform', 'followers', 'estimated_cpm', 'estimated_cpe', 'top_country', 'top_city']
        valid_default_cols = [col for col in default_cols if col in available_cols]
        
        cols_to_export = st.multiselect(
            "ì‹œë”© ëª©ë¡ì—ì„œ ë‚´ë³´ë‚¼ ì»¬ëŸ¼ ì„ íƒ", 
            options=available_cols, 
            default=valid_default_cols,
            key="export_multiselect" 
        )
        
        if not seeding_list_df.empty and cols_to_export:
            seeding_list_to_export = seeding_list_df[cols_to_export]
            
            st.download_button(
                label="âœ… ìµœì¢… ì‹œë”© ëª©ë¡ CSV ë‹¤ìš´ë¡œë“œ",
                data=to_csv(seeding_list_to_export),
                file_name="team_report_seeding_list.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        st.markdown("---")
        
        st.markdown("#### B. AI í†µí•© ë¶„ì„ ë¦¬í¬íŠ¸ (PDF)")
        
        if st.session_state.insight_report:
            report_name, insight_content = st.session_state.insight_report
            
            if report_name == selected_influencer_name:
                filter_report_content = "N/A (1ì°¨ ë³´ê³ ì„œ ì—†ìŒ)"
                if st.session_state.filter_report_file is not None:
                    filter_report_content = st.session_state.filter_report_file.getvalue().decode("utf-8")
                analysis_report_content = "N/A (ì¶”ê°€ ë³´ê³ ì„œ ì—†ìŒ)"
                if st.session_state.analysis_report_file is not None:
                    analysis_report_content = st.session_state.analysis_report_file.getvalue().decode("utf-8")
                
                pdf_bytes = generate_pdf_report(
                    seeding_list_df, insight_content, st.session_state.brand_fit_result[1] if st.session_state.brand_fit_result and st.session_state.brand_fit_result[0] == report_name else None,
                    st.session_state.persona_input, filter_report_content, analysis_report_content, report_name
                )
                
                st.download_button(
                    label=f"âœ… í†µí•© ë¦¬í¬íŠ¸ PDF ë‹¤ìš´ë¡œë“œ (for {report_name})",
                    data=pdf_bytes,
                    file_name=f"strategic_report_{report_name}.pdf",
                    mime="application/pdf",
                    use_container_width=True
                )
            else:
                st.warning(f"'4. AI ì‹¬ì¸µ ë¶„ì„' íƒ­ì—ì„œ í˜„ì¬ ì„ íƒëœ '{selected_influencer_name}'ì˜ ë¦¬í¬íŠ¸ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
        else:
            st.warning("ë¨¼ì € '4. AI ì‹¬ì¸µ ë¶„ì„' íƒ­ì—ì„œ 'í†µí•© ì¸ì‚¬ì´íŠ¸ ë³´ê³ ì„œ'ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.")

        st.divider()

        st.subheader("5.2 ì¸í”Œë£¨ì–¸ì„œ ê³„ì•½ì„œ ì´ˆì•ˆ ì‘ì„±")
        
        st.info(f"ê³„ì•½ ëŒ€ìƒ: **{selected_influencer_name}**")
        
        st.text_input("1. ì œì•ˆ ë¹„ìš© (e.g., $500 USD)", key='proposed_cost')
        st.text_input("2. ìº í˜ì¸ ê¸°ê°„ (e.g., 2025-12-01 ~ 2025-12-15)", key='campaign_period')
        st.text_area("3. ì½˜í…ì¸  ê°€ì´ë“œë¼ì¸", key='content_guideline', 
                         placeholder="ì˜ˆ: 12ì›” 10ì¼ê¹Œì§€ í‹±í†¡ ì˜ìƒ 1ê±´, ì¸ìŠ¤íƒ€ê·¸ë¨ ë¦´ìŠ¤ 1ê±´. ì œí’ˆì„ ìì—°ìŠ¤ëŸ½ê²Œ ë…¸ì¶œí•˜ë©°...")

        if st.button("AIë¡œ ê³„ì•½ì„œ ì´ˆì•ˆ ìƒì„±í•˜ê¸°", type="primary", use_container_width=True):
            cost = st.session_state.proposed_cost
            period = st.session_state.campaign_period
            guideline = st.session_state.content_guideline
            
            if not cost or not period or not guideline:
                st.error("ë¹„ìš©, ê¸°ê°„, ê°€ì´ë“œë¼ì¸ì„ ëª¨ë‘ ì…ë ¥í•´ì•¼ ê³„ì•½ì„œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            else:
                with st.spinner("GPT-4ê°€ d'Albaì™€ ì¸í”Œë£¨ì–¸ì„œ ê°„ì˜ ê³„ì•½ì„œ ì´ˆì•ˆì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        contract_draft = query_openai_api_for_contract(
                            selected_influencer_name, cost, period, guideline
                        )
                        st.session_state.generated_contract = (selected_influencer_name, contract_draft)
                    except Exception as e:
                        st.error(f"ê³„ì•½ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        if st.session_state.generated_contract and st.session_state.generated_contract[0] == selected_influencer_name:
            st.markdown("---")
            st.markdown("##### ğŸ’¡ AIê°€ ìƒì„±í•œ ê³„ì•½ì„œ ì´ˆì•ˆ")
            contract_name, contract_text = st.session_state.generated_contract
            st.text_area("Generated Contract", value=contract_text, height=400)
            
            pdf_contract = PDF(orientation='P', unit='mm', format='A4')
            pdf_contract.add_korean_fonts()
            pdf_contract.add_page()
            pdf_contract.chapter_body(contract_text)
            pdf_contract_bytes = bytes(pdf_contract.output(dest='S')) 

            st.download_button(
                label=f"âœï¸ {contract_name} ê³„ì•½ì„œ ì´ˆì•ˆ PDF ë‹¤ìš´ë¡œë“œ",
                data=pdf_contract_bytes,
                file_name=f"contract_draft_{contract_name}.pdf",
                mime="application/pdf",
                use_container_width=True
            )


# --- (V23) ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
def main():
    st.set_page_config(layout="wide")

    tab1, tab2 = st.tabs(["ğŸš€ ì‹œë”© í”Œë«í¼ (V23.1)", "âš™ï¸ ê°€ìƒ ë°ì´í„° ìƒì„±"])

    # --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (V23) ---
    if 'target_countries' not in st.session_state: st.session_state.target_countries = []
    if 'target_cities' not in st.session_state: st.session_state.target_cities = []
    if 'target_age_cols' not in st.session_state: st.session_state.target_age_cols = []
    if 'target_gender_cols' not in st.session_state: st.session_state.target_gender_cols = []
    if 'platform' not in st.session_state: st.session_state.platform = 'Any' 
    if 'min_followers' not in st.session_state: st.session_state.min_followers = 0 
    if 'max_followers' not in st.session_state: st.session_state.max_followers = 1000000 
    if 'min_engagement' not in st.session_state: st.session_state.min_engagement = 0.0
    if 'max_fake_followers' not in st.session_state: st.session_state.max_fake_followers = 30.0
    if 'target_threshold_pct' not in st.session_state: st.session_state.target_threshold_pct = 30.0 
    
    if 'persona_input' not in st.session_state: st.session_state.persona_input = ""
    if 'other_requirements_input' not in st.session_state: st.session_state.other_requirements_input = ""
    
    if 'brand_keywords_input_4' not in st.session_state: st.session_state.brand_keywords_input_4 = [] 
    if 'analysis_brand_guideline_input' not in st.session_state: st.session_state.analysis_brand_guideline_input = ""
    
    if 'proposed_cost' not in st.session_state: st.session_state.proposed_cost = ""
    if 'campaign_period' not in st.session_state: st.session_state.campaign_period = ""
    if 'content_guideline' not in st.session_state: st.session_state.content_guideline = ""
    if 'generated_contract' not in st.session_state: st.session_state.generated_contract = None
    
    if 'brand_fit_result' not in st.session_state: st.session_state.brand_fit_result = None
    if 'liked_influencers' not in st.session_state: st.session_state.liked_influencers = set()
    if 'insight_report' not in st.session_state: st.session_state.insight_report = None
    
    if 'country_dist_loaded' not in st.session_state: st.session_state.country_dist_loaded = None
    if 'city_dist_loaded' not in st.session_state: st.session_state.city_dist_loaded = None


    data_file = "influencers_v23.csv" 
    
    try:
        FPDF(orientation='P', unit='mm', format='A4').add_font('MalgunGothic', '', 'MALGUN.TTF')
        FPDF(orientation='P', unit='mm', format='A4').add_font('MalgunGothic', 'B', 'MALGUNBD.TTF')
    except Exception:
        st.warning("âš ï¸ **PDF ìƒì„±ì„ ìœ„í•´ í•œê¸€ í°íŠ¸ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.** 'MALGUN.TTF'ì™€ 'MALGUNBD.TTF' íŒŒì¼ì„ ì‹¤í–‰ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”. í˜„ì¬ëŠ” ê¸°ë³¸ í°íŠ¸ë¡œ ì¶œë ¥ë©ë‹ˆë‹¤.")
        
    try:
        df = pd.read_csv(data_file)
        
        if st.session_state.country_dist_loaded is None:
            st.session_state.country_dist_loaded = df['audience_country_dist'].apply(json.loads)
        if st.session_state.city_dist_loaded is None:
            st.session_state.city_dist_loaded = df['audience_city_dist'].apply(json.loads)

        if 'age_under_18' not in df.columns or 'top_country' not in df.columns: 
            st.error(f"ë°ì´í„° íŒŒì¼({data_file})ì´ V23 í˜•ì‹(Top N, Age í™•ì¥ í¬í•¨)ê³¼ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤. 'ê°€ìƒ ë°ì´í„° ìƒì„±' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ì¬ìƒì„±í•´ì£¼ì„¸ìš”.")
            with tab1:
                st.warning("'âš™ï¸ ê°€ìƒ ë°ì´í„° ìƒì„±' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ë¨¼ì € ì¬ìƒì„±í•´ì£¼ì„¸ìš”.")
            with tab2:
                st.warning("ë°ì´í„° íŒŒì¼ í˜•ì‹ì´ ë‹¤ë¦…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë®ì–´ì“°ì„¸ìš”.")
                if st.button("ê°€ìƒ ë°ì´í„° ì¬ìƒì„± (V23 í˜•ì‹ ë®ì–´ì“°ê¸°)"):
                    st.session_state.country_dist_loaded = None
                    st.session_state.city_dist_loaded = None
                    create_mock_data(data_file)
                    st.rerun()
        else:
            with tab1:
                run_app(df)
            with tab2:
                st.success(f"'{data_file}' íŒŒì¼ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. (V23 í˜•ì‹)")
                if st.button("ê°€ìƒ ë°ì´í„° ì¬ìƒì„± (ë®ì–´ì“°ê¸°)"):
                    st.session_state.country_dist_loaded = None
                    st.session_state.city_dist_loaded = None
                    create_mock_data(data_file)
                    st.rerun() 
                st.dataframe(df.head())
                
    except FileNotFoundError:
        with tab2:
            st.warning(f"'{data_file}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ê°€ìƒ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            if st.button("ê°€ìƒ ì¸í”Œë£¨ì–¸ì„œ 10,000ëª… ë°ì´í„° ìƒì„±í•˜ê¸°"):
                create_mock_data(data_file)
                st.rerun() 
        with tab1:
            st.info("'âš™ï¸ ê°€ìƒ ë°ì´í„° ìƒì„±' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main()