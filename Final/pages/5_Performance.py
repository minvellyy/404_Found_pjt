import streamlit as st
import pandas as pd
from typing import Set, Tuple
import numpy as np
import json
from openai import OpenAI
import pandas as pd
# ğŸ”¹ 'create_engine', 'os', 'load_dotenv'ëŠ” ë” ì´ìƒ í•„ìš” ì—†ìœ¼ë¯€ë¡œ ì‚­ì œ

# ğŸ”¹ DB ì ‘ì† ì •ë³´ë¥¼ secrets.tomlì—ì„œ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜¤ë¯€ë¡œ ê´€ë ¨ ì½”ë“œ ì‚­ì œ

# 2) products ë¶ˆëŸ¬ì˜¤ê¸°
query_products = """
SELECT
    p.product_id        AS ì œí’ˆID,
    p.brand_name        AS ë¸Œëœë“œëª…,
    p.product_name      AS ì œí’ˆëª…,
    p.category          AS ì¹´í…Œê³ ë¦¬,
    p.price             AS ê°€ê²©,
    p.text_keyword      AS `í•µì‹¬_ì„±ë¶„/í‚¤ì›Œë“œ`,
    p.visual_keyword    AS ë¸Œëœë“œ_ì´ë¯¸ì§€_íƒœê·¸,
    p.effect_keyword    AS íš¨ê³¼_í‚¤ì›Œë“œ,
    p.keyword_tag       AS í†µí•©_í‚¤ì›Œë“œ
FROM products p;
"""

# 3) influencers ë¶ˆëŸ¬ì˜¤ê¸°
query_influencers = """
SELECT
    i.influencer_id     AS ID,
    i.influencer_name   AS ì´ë¦„,
    i.handle            AS ê³„ì •í•¸ë“¤,
    i.platform          AS í”Œë«í¼,
    i.account_category  AS ê³„ì •_ì¹´í…Œê³ ë¦¬,
    i.niche             AS ë‹ˆì¹˜,
    i.follower_count    AS `íŒ”ë¡œì›Œ ìˆ˜`,
    i.avg_likes         AS í‰ê· _ì¢‹ì•„ìš”,
    i.avg_comments      AS í‰ê· _ëŒ“ê¸€,
    i.quality_grade     AS í’ˆì§ˆë“±ê¸‰,
    i.account_keywords  AS ì£¼ìš”_ì½˜í…ì¸ _í‚¤ì›Œë“œ,
    i.email             AS ì´ë©”ì¼
FROM influencers i;
"""

# 4) ìº í˜ì¸ ì„±ê³¼ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
query_results = """
SELECT
    cp.post_id                       AS Post_ID,
    c.campaign_id                    AS Campaign_ID,
    c.campaign_name                  AS ìº í˜ì¸ëª…,
    c.objective                      AS ìº í˜ì¸ëª©ì ,
    cp.influencer_id                 AS Influencer_ID,
    i.influencer_name                AS ì¸í”Œë£¨ì–¸ì„œëª…,
    i.handle                         AS ê³„ì •í•¸ë“¤,
    i.platform                       AS í”Œë«í¼,
    i.follower_count                 AS íŒ”ë¡œì›Œìˆ˜,
    i.quality_grade                  AS ì¸í”Œë£¨ì–¸ì„œë“±ê¸‰,
    cp.product_id                    AS ì œí’ˆID,
    p.brand_name                     AS ë¸Œëœë“œëª…,
    p.product_name                   AS ì œí’ˆëª…,
    p.category                       AS ì œí’ˆì¹´í…Œê³ ë¦¬,
    cp.post_date                     AS ê²Œì‹œì¼,
    cp.post_url                      AS ê²Œì‹œURL,
    cp.views                         AS ì¡°íšŒìˆ˜,
    cp.likes                         AS ì¢‹ì•„ìš”ìˆ˜,
    cp.comments                      AS ëŒ“ê¸€ìˆ˜,
    cp.saves                         AS ì €ì¥ìˆ˜,
    cp.cost                          AS ì´ë¹„ìš©,
    (cp.likes + cp.comments + cp.saves) / cp.views * 100    AS ì „í™˜ìœ¨,
    cp.saves / cp.views * 100                               AS ê¸ì •_ê°ì •ë¹„ìœ¨,
    cp.likes / cp.views * 100                               AS í´ë¦­ë¥ ,
    cp.cost / cp.likes                                      AS í´ë¦­ë‹¹ë¹„ìš©,
    cp.views                                                AS ë…¸ì¶œìˆ˜,
    cp.views * 0.8                                          AS ë„ë‹¬ìˆ˜
FROM campaign_posts cp
JOIN campaigns   c ON cp.campaign_id   = c.campaign_id
JOIN influencers i ON cp.influencer_id = i.influencer_id
JOIN products    p ON cp.product_id    = p.product_id;
"""

# --- dotenv ë¡œë“œ (ì‚­ì œ) ---

# -----------------------------------------------------------
# LLM Client ì´ˆê¸°í™” (ğŸ”¹ ìˆ˜ì •ë¨)
# -----------------------------------------------------------
@st.cache_resource
def get_openai_client():
    try:
        # ğŸŸ¢ [ìˆ˜ì •] st.secretsì—ì„œ "OPENAI_API_KEY" (ëŒ€ë¬¸ì)ë¥¼ ë°”ë¡œ ì½ì–´ì˜´
        api_key = st.secrets["OPENAI_API_KEY"]
        if not api_key:
            raise ValueError(
                "OPENAI_API_KEYê°€ .streamlit/secrets.tomlì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            )
        client = OpenAI(api_key=api_key)
        return client
    except KeyError: # ğŸŸ¢ 'KeyError'ë¥¼ ì¡ì•„ì„œ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
        st.error(
            "âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: .streamlit/secrets.toml íŒŒì¼ì— 'OPENAI_API_KEY'ê°€ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ì´ë¦„ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        )
        st.stop()
    except Exception as e:
        st.error(
            f"âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. .streamlit/secrets.toml íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
        )
        st.stop()

# -----------------------------------------------------------
# 1. LLM API í˜¸ì¶œ í•¨ìˆ˜: ë§ˆì¼€íŒ… ìš”ì²­ ë¶„ì„
# -----------------------------------------------------------
@st.cache_data(show_spinner="ğŸ§  LLMì´ ë§ˆì¼€íŒ… ìš”ì²­ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")
def call_llm_for_analysis(
    prompt: str, df_products: pd.DataFrame
) -> Tuple[Set[str], Set[str], str]:
    client = get_openai_client()

    SYSTEM_PROMPT = """
    ë‹¹ì‹ ì€ K-Beauty ë¸Œëœë“œì˜ ì‹œë‹ˆì–´ ë§ˆì¼€íŒ… AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
    ì‚¬ìš©ìì˜ ìš”ì²­(prompt)ì„ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì œí’ˆ í‚¤ì›Œë“œì™€ ì‹œê°ì  ê°ì„± íƒœê·¸ë¥¼ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
    ì¶œë ¥ì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì¤€ìˆ˜í•´ì•¼ í•©ë‹ˆë‹¤:
    {
      "text_keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", "í‚¤ì›Œë“œ3", ...],
      "visual_tags": ["íƒœê·¸1", "íƒœê·¸2", "íƒœê·¸3", ...]
    }

    í‚¤ì›Œë“œëŠ” ì œí’ˆ ì„±ë¶„/íš¨ëŠ¥(ì˜ˆ: íˆì•Œë£¨ë¡ ì‚°, ìˆ˜ë¶„, ë¯¸ë°±)ê³¼ ê´€ë ¨ë˜ì–´ì•¼ í•˜ë©°,
    íƒœê·¸ëŠ” ë¸Œëœë“œ ì´ë¯¸ì§€/í”¼ë“œ ê°ì„±(ì˜ˆ: ì‹œí¬, ì €ì±„ë„, íŠ¸ë Œë””)ê³¼ ê´€ë ¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    í‚¤ì›Œë“œì™€ íƒœê·¸ëŠ” ê°ê° ìµœì†Œ 3ê°œ, ìµœëŒ€ 5ê°œë¥¼ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.
    """

    product_list = df_products[
        ["ì œí’ˆëª…", "í•µì‹¬_ì„±ë¶„/í‚¤ì›Œë“œ", "ë¸Œëœë“œ_ì´ë¯¸ì§€_íƒœê·¸"]
    ].to_string(index=False)

    USER_PROMPT = f"""
    [ë§ˆì¼€í„° ìš”ì²­]: {prompt}

    [ì°¸ì¡° ê°€ëŠ¥í•œ K-Beauty ì œí’ˆ ëª©ë¡]:
    {product_list}

    ìœ„ ìš”ì²­ì— ê°€ì¥ ë¶€í•©í•˜ëŠ” 'text_keywords'ì™€ 'visual_tags'ë¥¼ JSON í˜•íƒœë¡œë§Œ ì¶œë ¥í•´ ì£¼ì„¸ìš”.
    """

    try:
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": USER_PROMPT},
            ],
            response_format={"type": "json_object"},
        )

        json_output = completion.choices[0].message.content
        analysis_result = json.loads(json_output)

        text_keywords_set = set(analysis_result.get("text_keywords", []))
        visual_tags_set = set(analysis_result.get("visual_tags", []))

        llm_summary = """**[LLM ë¶„ì„ ìš”ì•½]**
GenAI ëª¨ë¸ (**GPT-4o**)ì´ ë§ˆì¼€í„°ë‹˜ì˜ ìš”ì²­ì„ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.
ì¶”ì¶œëœ íŒŒë¼ë¯¸í„°ëŠ” ì¸í”Œë£¨ì–¸ì„œ ë§¤ì¹­ì— ì¦‰ì‹œ ì‚¬ìš©ë©ë‹ˆë‹¤.
"""

        return text_keywords_set, visual_tags_set, llm_summary

    except Exception as e:
        st.error(f"âŒ LLM API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}. GPT-4o ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        return (
            {"AI_ì‹¤íŒ¨", "ê¸°ë³¸_ìˆ˜ë¶„", "íŠ¸ë Œë””"},
            {"ì‹œí¬", "ë¯¸ë‹ˆë©€", "ì €ì±„ë„"},
            "**[LLM ë¶„ì„ ì‹¤íŒ¨]** API í˜¸ì¶œ ì‹¤íŒ¨. ì•ˆì „ì„ ìœ„í•´ ê¸°ë³¸ í‚¤ì›Œë“œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.",
        )


# -----------------------------------------------------------
# 2. LLM API í˜¸ì¶œ í•¨ìˆ˜: ì„±ì¥ ì§„ë‹¨ ë¦¬í¬íŠ¸ ìƒì„±
# -----------------------------------------------------------
def call_llm_for_growth_analysis(influencer_data: pd.Series) -> str:
    client = get_openai_client()

    er = (
        (
            influencer_data.get("í‰ê· _ì¢‹ì•„ìš”", 1000)
            + influencer_data.get("í‰ê· _ëŒ“ê¸€", 100)
        )
        / influencer_data["íŒ”ë¡œì›Œ ìˆ˜"]
        * 100
    )

    SYSTEM_PROMPT = "ë‹¹ì‹ ì€ ì¸í”Œë£¨ì–¸ì„œì˜ ìº í˜ì¸ ì„±ê³¼ ë°ì´í„°ì™€ ì½˜í…ì¸  íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ, ì„±ì¥ ì ì¬ë ¥ê³¼ êµ¬ì²´ì ì¸ ì•¡ì…˜ í”Œëœì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. í†¤ì€ ì „ë¬¸ì ì´ê³  ë…ë ¤í•˜ëŠ” ë°©ì‹ì´ì–´ì•¼ í•˜ë©°, ë³´ê³ ì„œ í˜•íƒœë¡œ ìƒì„¸í•˜ê²Œ (í•œêµ­ì–´ Markdownìœ¼ë¡œ) ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤."

    USER_DATA = f"""
    [ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°]:
    ì´ë¦„: {influencer_data['ì´ë¦„']}
    íŒ”ë¡œì›Œ: {influencer_data['íŒ”ë¡œì›Œ ìˆ˜']:,}ëª…
    í”Œë«í¼: {influencer_data['í”Œë«í¼']}
    ìº í˜ì¸ ì°¸ì—¬ íšŸìˆ˜: {influencer_data['ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜']}íšŒ
    í‰ê·  ì°¸ì—¬ìœ¨(ER): {er:.2f}%
    í‰ê·  ì „í™˜ìœ¨: {influencer_data['í‰ê· _ì „í™˜ìœ¨']:.2f}%
    í‰ê·  CTR: {influencer_data['í‰ê· _CTR']:.2f}%
    í‰ê·  CPC: {influencer_data['í‰ê· _CPC']:.0f}ì›
    í‰ê·  CPA: {influencer_data['í‰ê· _CPA']:.0f}ì›
    í‰ê·  CPR: {influencer_data['í‰ê· _CPR']:.0f}ì›
    ì£¼ìš” ì½˜í…ì¸  í‚¤ì›Œë“œ: {influencer_data['ì£¼ìš”_ì½˜í…ì¸ _í‚¤ì›Œë“œ']}
    í‰ê·  í”¼ë“œ ê°ì„± íƒœê·¸: {influencer_data['í‰ê· _í”¼ë“œ_ê°ì„±_íƒœê·¸']}

    ìœ„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ êµ¬ì„±ìœ¼ë¡œ 'ì„±ì¥ ì ì¬ë ¥ ì§„ë‹¨ ë¦¬í¬íŠ¸'ë¥¼ 250ì ë‚´ì™¸ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”:
    1. í•µì‹¬ ì½˜í…ì¸  ê°•ì  (ë°ì´í„° ê¸°ë°˜ì˜ ì„±ê³¼)
    2. ì½˜í…ì¸  ì•½ì  ë° ì„±ì¥ ì œì•ˆ (êµ¬ì²´ì ì¸ Action Plan í¬í•¨)
    """

    try:
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": USER_DATA},
            ],
        )
        return completion.choices[0].message.content

    except Exception as e:
        return (
            f"## âš ï¸ AI ì§„ë‹¨ ì‹¤íŒ¨\nLLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}\n(ë°ì´í„° ê¸°ë°˜ ì„±ì¥ ì§„ë‹¨ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.)"
        )


# -----------------------------------------------------------
# 3. LLM API í˜¸ì¶œ í•¨ìˆ˜: ì „ì²´ KPI ìš”ì•½ ë³´ê³ ì„œ ìƒì„±
# -----------------------------------------------------------
@st.cache_data(show_spinner="âœï¸ LLMì´ ì „ì²´ KPI ìš”ì•½ ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤...")
def call_llm_for_kpi_summary(df_influencers: pd.DataFrame, w_config: dict) -> str:
    client = get_openai_client()

    # ì „ëµì _ì„±ê³¼_ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (df_influencersì—ëŠ” ì´ë¯¸ ì ìˆ˜ê°€ ë“¤ì–´ìˆë‹¤ê³  ê°€ì •)
    df_sorted = df_influencers.sort_values(
        "ì „ëµì _ì„±ê³¼_ì ìˆ˜", ascending=False
    )

    top_kpi_data = df_sorted.head(5)[
        ["ì´ë¦„", "í‰ê· _CPR", "í‰ê· _CPA", "í‰ê· _ì „í™˜ìœ¨", "ì£¼ìš”_ì½˜í…ì¸ _í‚¤ì›Œë“œ"]
    ].to_string(index=False)
    bottom_kpi_data = df_sorted.tail(5)[
        ["ì´ë¦„", "í‰ê· _CPR", "í‰ê· _CPA", "í‰ê· _ì „í™˜ìœ¨", "ì£¼ìš”_ì½˜í…ì¸ _í‚¤ì›Œë“œ"]
    ].to_string(index=False)

    SYSTEM_PROMPT = "ë‹¹ì‹ ì€ K-Beauty ë¸Œëœë“œì˜ CMO(ìµœê³  ë§ˆì¼€íŒ… ì±…ì„ì)ì—ê²Œ ë³´ê³ í•˜ëŠ” ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì¼€íŒ… íš¨ìœ¨ì„±, ë¹„ìš© ì„±ê³¼(CPA/CPR), ê·¸ë¦¬ê³  ì½˜í…ì¸  íŠ¸ë Œë“œì— ëŒ€í•œ í•µì‹¬ í†µì°°ë ¥ì„ ë‹´ì•„ ì „ë¬¸ì ì¸ (í•œêµ­ì–´ Markdownìœ¼ë¡œ) ìš”ì•½ ë³´ê³ ì„œë¥¼ 500ì ë‚´ì™¸ë¡œ ìƒì„¸í•˜ê²Œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤."

    USER_DATA = f"""
    [í˜„ì¬ ë§ˆì¼€íŒ… ì „ëµ ê°€ì¤‘ì¹˜]:
    - ì°¸ì—¬ìœ¨(ER): {w_config['w_er']:.2f}, CPR: {w_config['w_cpr']:.2f}, ë„ë‹¬ìˆ˜: {w_config['w_reach']:.2f},
    - CPA: {w_config['w_cpa']:.2f}, CPM: {w_config['w_cpm']:.2f}

    [ìµœì¢… íš¨ìœ¨ì„± ìˆœìœ„ Top 5 ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ìš”ì•½]:
    {top_kpi_data}

    [ìµœì¢… íš¨ìœ¨ì„± ìˆœìœ„ Bottom 5 ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° ìš”ì•½]:
    {bottom_kpi_data}

    ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, **'í˜„ì¬ ì „ëµì— ë”°ë¥¸ ë§ˆì¼€íŒ… íš¨ìœ¨ì„± ì§„ë‹¨'**ê³¼ **'í–¥í›„ ìº í˜ì¸ ë°©í–¥ì„±ì— ëŒ€í•œ í•µì‹¬ ì œì•ˆ'**ì„ í¬í•¨í•˜ëŠ” ë³´ê³ ì„œë¥¼ ì‘ì„±í•´ ì£¼ì„¸ìš”.
    """

    try:
        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": USER_DATA},
            ],
        )
        return completion.choices[0].message.content
    except Exception as e:
        return (
            f"## âš ï¸ AI ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨\nLLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}\n(ì „ì²´ KPI ë¶„ì„ ë³´ê³ ì„œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.)"
        )


# --- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ğŸ”¹ ìˆ˜ì •ë¨) ---
@st.cache_data
def load_data():
    try:
        # ğŸ”¹ st.connectionì„ ì‚¬ìš©í•˜ì—¬ secrets.tomlì˜ "mysql_db" ì—°ê²° ì •ë³´ë¥¼ ì‚¬ìš©
        conn = st.connection("mysql_db", type="sql")
        
        # ğŸ”¹ conn.query()ë¥¼ ì‚¬ìš©í•´ DataFrameìœ¼ë¡œ ë°”ë¡œ ë¡œë“œ
        df_products = conn.query(query_products)
        df_influencers = conn.query(query_influencers)
        df_results = conn.query(query_results)

        # ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€
        df_influencers['í‰ê· _í”¼ë“œ_ê°ì„±_íƒœê·¸'] = df_influencers['ì£¼ìš”_ì½˜í…ì¸ _í‚¤ì›Œë“œ']
        
        def keyword_to_set(keyword_str):
            if isinstance(keyword_str, str):
                return set(keyword_str.replace(" ", "").split(","))
            return set()

        df_products["í…ìŠ¤íŠ¸_í‚¤ì›Œë“œ_SET"] = df_products["í•µì‹¬_ì„±ë¶„/í‚¤ì›Œë“œ"].apply(
            keyword_to_set
        )
        df_products["ì‹œê°_í‚¤ì›Œë“œ_SET"] = df_products["ë¸Œëœë“œ_ì´ë¯¸ì§€_íƒœê·¸"].apply(
            keyword_to_set
        )
        df_influencers["í…ìŠ¤íŠ¸_í‚¤ì›Œë“œ_SET"] = df_influencers["ì£¼ìš”_ì½˜í…ì¸ _í‚¤ì›Œë“œ"].apply(
            keyword_to_set
        )
        df_influencers["ì‹œê°_í‚¤ì›Œë“œ_SET"] = df_influencers["í‰ê· _í”¼ë“œ_ê°ì„±_íƒœê·¸"].apply(
            keyword_to_set
        )

        df_influencers_with_results = df_influencers.merge(
            df_results.groupby("Influencer_ID").agg(
                ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜=("Campaign_ID", "count"),
                í‰ê· _ì „í™˜ìœ¨=("ì „í™˜ìœ¨", "mean"),
                í‰ê· _ê¸ì •_ê°ì •ë¹„ìœ¨=("ê¸ì •_ê°ì •ë¹„ìœ¨", "mean"),
                í‰ê· _CTR=("í´ë¦­ë¥ ", "mean"),
                í‰ê· _CPC=("í´ë¦­ë‹¹ë¹„ìš©", "mean"),
                í‰ê· _ë…¸ì¶œìˆ˜=("ë…¸ì¶œìˆ˜", "mean"),
                í‰ê· _ë„ë‹¬ìˆ˜=("ë„ë‹¬ìˆ˜", "mean"),
                í‰ê· _ì´ë¹„ìš©=("ì´ë¹„ìš©", "mean"),
            ).reset_index(),
            left_on="ID",
            right_on="Influencer_ID",
            how="left",
        ).fillna(0)

        df_influencers_with_results["í‰ê· _CPM"] = (
            df_influencers_with_results["í‰ê· _ì´ë¹„ìš©"]
            / df_influencers_with_results["í‰ê· _ë…¸ì¶œìˆ˜"]
        ).replace([np.inf, -np.inf], 0).fillna(0) * 1000
        
        df_influencers_with_results["í‰ê· _CPR"] = (
            df_influencers_with_results["í‰ê· _ì´ë¹„ìš©"]
            / df_influencers_with_results["í‰ê· _ë„ë‹¬ìˆ˜"]
        ).replace([np.inf, -np.inf], 0).fillna(0)
        
        safe_conversion = df_influencers_with_results["í‰ê· _ë„ë‹¬ìˆ˜"] * (
            df_influencers_with_results["í‰ê· _ì „í™˜ìœ¨"] / 100
        )
        safe_conversion = safe_conversion.replace(0, 1e-6)
        df_influencers_with_results["í‰ê· _CPA"] = (
            df_influencers_with_results["í‰ê· _ì´ë¹„ìš©"] / safe_conversion
        ).replace([np.inf, -np.inf], 0).fillna(0)

        # ğŸ”¥ ì§„ì •ì„± ì§€ìˆ˜ ê³„ì‚° (ì°¸ì—¬ìœ¨, ì „í™˜ìœ¨, ê¸ì • ê°ì • ë¹„ìœ¨ ê¸°ë°˜)
        # ì°¸ì—¬ìœ¨ ê³„ì‚°
        er = (
            (df_influencers_with_results["í‰ê· _ì¢‹ì•„ìš”"] + df_influencers_with_results["í‰ê· _ëŒ“ê¸€"])
            / df_influencers_with_results["íŒ”ë¡œì›Œ ìˆ˜"]
            * 100
        )
        
        # ì§„ì •ì„± ì§€ìˆ˜ = (ì°¸ì—¬ìœ¨ ì •ê·œí™” * 0.4) + (ì „í™˜ìœ¨ ì •ê·œí™” * 0.3) + (ê¸ì •ê°ì • ì •ê·œí™” * 0.3)
        # ê° ì§€í‘œë¥¼ 0-100 ë²”ìœ„ë¡œ ì •ê·œí™”
        er_normalized = np.minimum(er / 10 * 100, 100)  # ER 10%ë¥¼ 100ì ìœ¼ë¡œ
        conversion_normalized = np.minimum(df_influencers_with_results["í‰ê· _ì „í™˜ìœ¨"] / 5 * 100, 100)  # ì „í™˜ìœ¨ 5%ë¥¼ 100ì ìœ¼ë¡œ
        sentiment_normalized = df_influencers_with_results["í‰ê· _ê¸ì •_ê°ì •ë¹„ìœ¨"]  # ì´ë¯¸ 0-100 ë²”ìœ„
        
        df_influencers_with_results["ì§„ì •ì„±_ì§€ìˆ˜"] = (
            er_normalized * 0.4 + 
            conversion_normalized * 0.3 + 
            sentiment_normalized * 0.3
        ).fillna(50)  # ìº í˜ì¸ ì´ë ¥ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ 50
        
        # 0-100 ë²”ìœ„ë¡œ í´ë¦¬í•‘
        df_influencers_with_results["ì§„ì •ì„±_ì§€ìˆ˜"] = df_influencers_with_results["ì§„ì •ì„±_ì§€ìˆ˜"].clip(0, 100)

        cost_cols = ["í‰ê· _CPM", "í‰ê· _CPR", "í‰ê· _CPA"]
        for col in cost_cols:
            if (
                df_influencers_with_results[col]
                .replace([np.inf, -np.inf], 0)
                .max()
                > 0
            ):
                no_history_value = (
                    df_influencers_with_results[
                        df_influencers_with_results["ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜"] > 0
                    ][col]
                    .replace([np.inf, -np.inf], 0)
                    .max()
                    * 1.1
                )
                df_influencers_with_results.loc[
                    df_influencers_with_results["ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜"] == 0, col
                ] = no_history_value if no_history_value > 0 else 1000000
            else:
                df_influencers_with_results.loc[
                    df_influencers_with_results["ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜"] == 0, col
                ] = 1000000

        df_influencers_with_results.loc[
            df_influencers_with_results["ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜"] == 0,
            ["í‰ê· _ë„ë‹¬ìˆ˜", "í‰ê· _ì´ë¹„ìš©", "í‰ê· _ë…¸ì¶œìˆ˜"],
        ] = 0
        df_influencers_with_results = df_influencers_with_results.fillna(0)

        # ì´ˆê¸°í™”ìš© ì»¬ëŸ¼
        df_influencers_with_results["ì „ëµì _ì„±ê³¼_ì ìˆ˜"] = 0.0

        return df_products, df_influencers_with_results
    
    # ğŸ”¹ ì—ëŸ¬ í•¸ë“¤ë§ ìˆ˜ì •
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë˜ëŠ” ì¿¼ë¦¬ ì‹¤íŒ¨: {e}")
        st.error("'.streamlit/secrets.toml' íŒŒì¼ì˜ [connections.mysql_db] ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame(), pd.DataFrame()


# --- ê³µí†µ í•¨ìˆ˜ ---
def calculate_jaccard_similarity(set1: Set[str], set2: Set[str]) -> float:
    if not set1 and not set2:
        return 0.0
    intersection = len(set1.intersection(set2))
    union = len(set1.union(set2))
    return intersection / union


# --- íƒ­ 1: ë§¤ì¹­ ëª¨ë“ˆ ---
# (ì´ ì½”ë“œëŠ” ì¡´ì¬í•˜ì§€ë§Œ, ì•„ë˜ app() ì •ì˜ì—ì„œ í˜¸ì¶œë˜ì§€ ì•ŠìŒ)
def matching_module(df_products: pd.DataFrame, df_influencers: pd.DataFrame):
    st.title("ğŸ§  ìƒì„±í˜• AI ê¸°ë°˜ ë§ì¶¤í˜• ì¸í”Œë£¨ì–¸ì„œ ë§¤ì¹­")
    st.markdown(
        "ë§ˆì¼€íŒ… ìš”ì²­ì„ ìì—°ì–´ë¡œ ì…ë ¥í•˜ë©´, **GPT-4o**ê°€ ìë™ìœ¼ë¡œ í‚¤ì›Œë“œì™€ ê°ì„±ì„ ì¶”ì¶œí•˜ì—¬ ì¸í”Œë£¨ì–¸ì„œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤."
    )
    st.markdown("---")

    W_CONTENT = 0.6
    W_STRATEGY = 0.4

    w_er = st.session_state.get("w_er", 0.35)
    w_cpr = st.session_state.get("w_cpr", 0.25)
    w_reach = st.session_state.get("w_reach", 0.20)
    w_cpa = st.session_state.get("w_cpa", 0.10)
    w_cpm = st.session_state.get("w_cpm", 0.10)

    left_col, right_col = st.columns([1, 2])

    with left_col:
        st.header("1. ë§ˆì¼€íŒ… ìš”êµ¬ì‚¬í•­ ì…ë ¥ (LLM Prompt)")
        prompt = st.text_area(
            "ì›í•˜ëŠ” ì œí’ˆ/ë¸Œëœë“œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì„¤ëª…í•˜ì„¸ìš”:",
            value="ìš”ì¦˜ MZ ì„¸ëŒ€ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ, ìˆ˜ë¶„ ë³´ì¶©ì´ í™•ì‹¤í•˜ê³  ì¸ìŠ¤íƒ€ ê°ì„±ì´ ì˜ ë§ëŠ” ì‹œí¬í•œ ë¬´ë“œì˜ ë§ˆì´í¬ë¡œ ì¸í”Œë£¨ì–¸ì„œë¥¼ ì¶”ì²œí•´ì¤˜.",
            height=150,
        )

        if not prompt:
            st.warning("ë§ˆì¼€íŒ… ìš”êµ¬ì‚¬í•­ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
            return

        text_keywords_set, visual_tags_set, llm_summary = call_llm_for_analysis(
            prompt, df_products
        )

        st.markdown("---")
        st.header("2. LLM ë¶„ì„ ê²°ê³¼")
        st.markdown(llm_summary)
        st.markdown(f"**í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ:** `{', '.join(text_keywords_set)}`")
        st.markdown(f"**ì‹œê°ì  ê°ì„± íƒœê·¸:** `{', '.join(visual_tags_set)}`")
        st.markdown("---")

        st.subheader("3. í˜„ì¬ ì ìš©ëœ ë§¤ì¹­ ì „ëµ")
        st.info(
            f"**ì½˜í…ì¸  ì í•©ë„({W_CONTENT*100:.0f}%)**ì™€ **ì „ëµì  ì„±ê³¼({W_STRATEGY*100:.0f}%)**ë¥¼ í•©ì‚°í•©ë‹ˆë‹¤."
        )
        st.markdown(
            f"**ì „ëµì  ì„±ê³¼ ê°€ì¤‘ì¹˜:** ER({w_er:.2f}), CPR({w_cpr:.2f}), ë„ë‹¬({w_reach:.2f}), CPA({w_cpa:.2f}), CPM({w_cpm:.2f})"
        )
        st.markdown("ì´ ê°€ì¤‘ì¹˜ëŠ” **'ğŸ“Š ì„±ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ' íƒ­**ì—ì„œ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    with right_col:
        df_valid = (
            df_influencers[df_influencers["ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜"] > 0]
            .replace([np.inf, -np.inf], np.nan)
            .dropna(subset=["í‰ê· _CPR", "í‰ê· _CPA", "í‰ê· _CPM", "í‰ê· _ë„ë‹¬ìˆ˜"])
        )
        min_cpr, max_cpr = df_valid["í‰ê· _CPR"].min(), df_valid["í‰ê· _CPR"].max()
        min_cpa, max_cpa = df_valid["í‰ê· _CPA"].min(), df_valid["í‰ê· _CPA"].max()
        min_cpm, max_cpm = df_valid["í‰ê· _CPM"].min(), df_valid["í‰ê· _CPM"].max()
        min_reach, max_reach = (
            df_valid["í‰ê· _ë„ë‹¬ìˆ˜"].min(),
            df_valid["í‰ê· _ë„ë‹¬ìˆ˜"].max(),
        )
        er_max_limit = 10.0

        results = []
        for _, influencer in df_influencers.iterrows():
            text_score = (
                calculate_jaccard_similarity(
                    text_keywords_set, influencer["í…ìŠ¤íŠ¸_í‚¤ì›Œë“œ_SET"]
                )
                * 100
            )
            visual_score = (
                calculate_jaccard_similarity(
                    visual_tags_set, influencer["ì‹œê°_í‚¤ì›Œë“œ_SET"]
                )
                * 100
            )
            final_matching_score = (W_CONTENT * text_score) + (
                (1.0 - W_CONTENT) * visual_score
            )

            matched_text_keywords = text_keywords_set.intersection(
                influencer["í…ìŠ¤íŠ¸_í‚¤ì›Œë“œ_SET"]
            )
            matched_visual_tags = visual_tags_set.intersection(
                influencer["ì‹œê°_í‚¤ì›Œë“œ_SET"]
            )

            er = (
                (
                    influencer.get("í‰ê· _ì¢‹ì•„ìš”", 1000)
                    + influencer.get("í‰ê· _ëŒ“ê¸€", 100)
                )
                / influencer["íŒ”ë¡œì›Œ ìˆ˜"]
                * 100
            )
            er_score = np.minimum((er / er_max_limit) * 100, 100)

            if (
                influencer["ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜"] > 0
                and max_cpr > min_cpr
                and max_cpa > min_cpa
                and max_cpm > min_cpm
            ):
                cpr_score = (
                    1 - (influencer["í‰ê· _CPR"] - min_cpr) / (max_cpr - min_cpr)
                ) * 100
                cpa_score = (
                    1 - (influencer["í‰ê· _CPA"] - min_cpa) / (max_cpa - min_cpa)
                ) * 100
                cpm_score = (
                    1 - (influencer["í‰ê· _CPM"] - min_cpm) / (max_cpm - min_cpm)
                ) * 100
                reach_score = (
                    influencer["í‰ê· _ë„ë‹¬ìˆ˜"] / max_reach * 100 if max_reach > 0 else 0
                )
            else:
                cpr_score, cpa_score, cpm_score = 0, 0, 0
                reach_score = 0

            strategy_score = (
                er_score * w_er
                + cpr_score * w_cpr
                + reach_score * w_reach
                + cpa_score * w_cpa
                + cpm_score * w_cpm
            )

            final_total_score = (
                final_matching_score * W_CONTENT + strategy_score * W_STRATEGY
            )

            results.append(
                {
                    "ì´ë¦„": influencer["ì´ë¦„"],
                    "í”Œë«í¼": influencer["í”Œë«í¼"],
                    "íŒ”ë¡œì›Œ ìˆ˜": influencer["íŒ”ë¡œì›Œ ìˆ˜"],
                    "ì°¸ì—¬ìœ¨ (ER)": f"{er:.2f}%",
                    "ì½˜í…ì¸ _ì í•©ë„": final_matching_score,
                    "ì „ëµì _ì„±ê³¼_ì ìˆ˜": strategy_score,
                    "ìµœì¢…_ì¢…í•©_ì ìˆ˜": final_total_score,
                    "ì¼ì¹˜_í‚¤ì›Œë“œ": ", ".join(matched_text_keywords)
                    if matched_text_keywords
                    else "ì—†ìŒ",
                    "ì¼ì¹˜_ê°ì„±_íƒœê·¸": ", ".join(matched_visual_tags)
                    if matched_visual_tags
                    else "ì—†ìŒ",
                    "ID": influencer["ID"],
                }
            )

        df_results_match = pd.DataFrame(results)
        df_results_sorted = df_results_match.sort_values(
            by="ìµœì¢…_ì¢…í•©_ì ìˆ˜", ascending=False
        )

        st.header("âœ¨ AI ë§¤ì¹­ ê²°ê³¼: ì¸í”Œë£¨ì–¸ì„œ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸")

        top_5 = df_results_sorted.head(5).copy()
        top_5.index = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "4ï¸âƒ£", "5ï¸âƒ£"]

        st.subheader("â­ ì¶”ì²œ ì¸í”Œë£¨ì–¸ì„œ (Top 5)")
        st.dataframe(
            top_5[
                [
                    "ì´ë¦„",
                    "ìµœì¢…_ì¢…í•©_ì ìˆ˜",
                    "ì½˜í…ì¸ _ì í•©ë„",
                    "ì „ëµì _ì„±ê³¼_ì ìˆ˜",
                    "ì°¸ì—¬ìœ¨ (ER)",
                    "ì¼ì¹˜_í‚¤ì›Œë“œ",
                    "ì¼ì¹˜_ê°ì„±_íƒœê·¸",
                ]
            ],
            column_config={
                "ìµœì¢…_ì¢…í•©_ì ìˆ˜": st.column_config.ProgressColumn(
                    "ìµœì¢… ì ìˆ˜ (100)",
                    format="%.1fì ",
                    min_value=0,
                    max_value=100,
                    help="ì½˜í…ì¸  ì í•©ë„ì™€ ì „ëµì  ì„±ê³¼ì˜ ê°€ì¤‘ í‰ê· ",
                ),
                "ì½˜í…ì¸ _ì í•©ë„": st.column_config.NumberColumn(
                    "ì½˜í…ì¸  ì í•©ë„", format="%.1fì "
                ),
                "ì „ëµì _ì„±ê³¼_ì ìˆ˜": st.column_config.NumberColumn(
                    "ì „ëµì  ì„±ê³¼", format="%.1fì "
                ),
                "ì°¸ì—¬ìœ¨ (ER)": st.column_config.TextColumn("ì°¸ì—¬ìœ¨ (ER)"),
            },
            width='stretch',
        )

        # ì œí’ˆ ì„ íƒ ì„¹ì…˜ (selected_product ì˜¤ë¥˜ ìˆ˜ì • ë²„ì „ ê·¸ëŒ€ë¡œ ìœ ì§€)
        st.markdown("---")
        st.subheader("ğŸ“¦ ì´ë²ˆ ìº í˜ì¸ì—ì„œ ì‚¬ìš©í•  ì œí’ˆ ì„ íƒ")

        product_names = df_products["ì œí’ˆëª…"].unique().tolist()
        if product_names:
            if "selected_product" not in st.session_state:
                st.session_state.selected_product = product_names[0]

            default_index = (
                product_names.index(st.session_state.selected_product)
                if st.session_state.selected_product in product_names
                else 0
            )

            selected_product = st.selectbox(
                "ìº í˜ì¸ ì œí’ˆì„ ì„ íƒí•˜ì„¸ìš”:",
                product_names,
                index=default_index,
                key="selected_product",
            )

            st.caption(f"ì„ íƒëœ ì œí’ˆ: **{selected_product}**")
        else:
            st.info("ë“±ë¡ëœ ì œí’ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")


# --- íƒ­ 2: ì„±ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ ---
def kpi_dashboard_module(df_influencers: pd.DataFrame):
    st.title("ğŸ“Š Performance")
    st.markdown(
        "KPI ì •ì˜ë¥¼ í™•ì¸í•˜ê³ , ì¸í”Œë£¨ì–¸ì„œ ë§¤ì¹­ì— ë°˜ì˜ë  **ì „ëµì  ì„±ê³¼ ê°€ì¤‘ì¹˜**ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤. **ê°€ì¤‘ì¹˜ì— ë”°ë¼ ìˆœìœ„ê°€ ë³€ê²½**ë©ë‹ˆë‹¤."
    )
    st.markdown("---")

    
    st.header("1. ì „ëµì  ì„±ê³¼ ê°€ì¤‘ì¹˜ ì„¤ì •")
    st.markdown(
        "ì¸í”Œë£¨ì–¸ì„œ ë§¤ì¹­ ì‹œ, KPI ì¤‘ ì–´ë–¤ ì§€í‘œì˜ íš¨ìœ¨ì„ ë” ì¤‘ìš”í•˜ê²Œ í‰ê°€í• ì§€ ê²°ì •í•©ë‹ˆë‹¤. (ì´í•© 1.00)"
    )

    if "w_er" not in st.session_state:
        st.session_state.w_er = 0.35
        st.session_state.w_cpr = 0.25
        st.session_state.w_reach = 0.20
        st.session_state.w_cpa = 0.10
        st.session_state.w_cpm = 0.10

    w_er = st.slider(
        "ì°¸ì—¬ìœ¨(ER) ê°€ì¤‘ì¹˜", 0.0, 1.0, st.session_state.w_er, 0.05, key="slider_er"
    )
    w_cpr = st.slider(
        "CPR ê°€ì¤‘ì¹˜", 0.0, 1.0, st.session_state.w_cpr, 0.05, key="slider_cpr"
    )
    w_reach = st.slider(
        "ë„ë‹¬ìˆ˜ ê°€ì¤‘ì¹˜",
        0.0,
        1.0,
        st.session_state.w_reach,
        0.05,
        key="slider_reach",
    )
    w_cpa = st.slider(
        "CPA ê°€ì¤‘ì¹˜", 0.0, 1.0, st.session_state.w_cpa, 0.05, key="slider_cpa"
    )
    w_cpm = st.slider(
        "CPM ê°€ì¤‘ì¹˜", 0.0, 1.0, st.session_state.w_cpm, 0.05, key="slider_cpm"
    )

    total_w = w_er + w_cpr + w_reach + w_cpa + w_cpm
    if total_w > 0:
        st.session_state.w_er = w_er / total_w
        st.session_state.w_cpr = w_cpr / total_w
        st.session_state.w_reach = w_reach / total_w
        st.session_state.w_cpa = w_cpa / total_w
        st.session_state.w_cpm = w_cpm / total_w
    else:
        st.session_state.w_er = 0.2
        st.session_state.w_cpr = 0.2
        st.session_state.w_reach = 0.2
        st.session_state.w_cpa = 0.2
        st.session_state.w_cpm = 0.2

    st.success(
        f"**ì´ ê°€ì¤‘ì¹˜ í•©ê³„:** {st.session_state.w_er + st.session_state.w_cpr + st.session_state.w_reach + st.session_state.w_cpa + st.session_state.w_cpm:.2f} (ìë™ ì •ê·œí™”)"
    )

    st.markdown("---")

    # --- 3. ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¸í”Œë£¨ì–¸ì„œ íš¨ìœ¨ì„± ìˆœìœ„ ---
    st.header("2. ì „ëµì  ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì¸í”Œë£¨ì–¸ì„œ íš¨ìœ¨ì„± ìˆœìœ„ (Top 10)")

    df_temp = df_influencers.copy()
    df_temp = df_temp[df_temp["ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜"] > 0]

    if not df_temp.empty:
        df_valid = (
            df_temp.replace([np.inf, -np.inf], np.nan)
            .dropna(subset=["í‰ê· _CPR", "í‰ê· _CPA", "í‰ê· _CPM", "í‰ê· _ë„ë‹¬ìˆ˜"])
        )
        min_cpr, max_cpr = df_valid["í‰ê· _CPR"].min(), df_valid["í‰ê· _CPR"].max()
        min_cpa, max_cpa = df_valid["í‰ê· _CPA"].min(), df_valid["í‰ê· _CPA"].max()
        min_cpm, max_cpm = df_valid["í‰ê· _CPM"].min(), df_valid["í‰ê· _CPM"].max()
        min_reach, max_reach = (
            df_valid["í‰ê· _ë„ë‹¬ìˆ˜"].min(),
            df_valid["í‰ê· _ë„ë‹¬ìˆ˜"].max(),
        )
        er_max_limit = 10.0

        er = (
            (
                df_temp.get("í‰ê· _ì¢‹ì•„ìš”", 1000)
                + df_temp.get("í‰ê· _ëŒ“ê¸€", 100)
            )
            / df_temp["íŒ”ë¡œì›Œ ìˆ˜"]
            * 100
        )
        er_score = np.minimum((er / er_max_limit) * 100, 100)

        cpr_score = (
            (1 - (df_temp["í‰ê· _CPR"] - min_cpr) / (max_cpr - min_cpr)) * 100
            if max_cpr > min_cpr
            else 0
        )
        cpa_score = (
            (1 - (df_temp["í‰ê· _CPA"] - min_cpa) / (max_cpa - min_cpa)) * 100
            if max_cpa > min_cpa
            else 0
        )
        cpm_score = (
            (1 - (df_temp["í‰ê· _CPM"] - min_cpm) / (max_cpm - min_cpm)) * 100
            if max_cpm > min_cpm
            else 0
        )
        reach_score = (
            df_temp["í‰ê· _ë„ë‹¬ìˆ˜"] / max_reach * 100 if max_reach > 0 else 0
        )

        df_temp["ì „ëµì _ì„±ê³¼_ì ìˆ˜"] = (
            er_score * st.session_state.w_er
            + cpr_score * st.session_state.w_cpr
            + reach_score * st.session_state.w_reach
            + cpa_score * st.session_state.w_cpa
            + cpm_score * st.session_state.w_cpm
        )

        df_sorted_strategy = df_temp.sort_values(
            "ì „ëµì _ì„±ê³¼_ì ìˆ˜", ascending=False
        )

        st.dataframe(
            df_sorted_strategy[
                ["ì´ë¦„", "íŒ”ë¡œì›Œ ìˆ˜", "ì „ëµì _ì„±ê³¼_ì ìˆ˜", "í‰ê· _CPR", "í‰ê· _CPA", "í‰ê· _ì „í™˜ìœ¨"]
            ].head(10),
            column_config={
                "ì „ëµì _ì„±ê³¼_ì ìˆ˜": st.column_config.ProgressColumn(
                    "ì „ëµì  íš¨ìœ¨ì„± (100)",
                    format="%.1fì ",
                    min_value=0,
                    max_value=100,
                    help="ì„¤ì •í•œ ê°€ì¤‘ì¹˜ì— ë”°ë¥¸ ì¢…í•© ì„±ê³¼ ì ìˆ˜",
                ),
                "í‰ê· _CPR": st.column_config.NumberColumn(
                    "í‰ê·  CPR (ì›)", format="%.0f"
                ),
                "í‰ê· _CPA": st.column_config.NumberColumn(
                    "í‰ê·  CPA (ì›)", format="%.0f"
                ),
                "í‰ê· _ì „í™˜ìœ¨": st.column_config.NumberColumn(
                    "í‰ê·  CR (%)", format="%.2f"
                ),
            },
            hide_index=True,
            width='stretch',
        )
    else:
        st.info("ìº í˜ì¸ ì´ë ¥ì´ ìˆëŠ” ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„°ê°€ ì—†ì–´ ìˆœìœ„ë¥¼ ë§¤ê¸¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    # --- 4. GenAI KPI ìš”ì•½ ë³´ê³ ì„œ ---
    st.header("3. ğŸ“ ì „ì²´ KPI ìš”ì•½ ë° ë§ˆì¼€íŒ… ì „ëµ ì œì–¸")

    kpi_summary_key = "kpi_summary_report"
    if kpi_summary_key not in st.session_state:
        st.session_state[kpi_summary_key] = None

    with st.form(key="kpi_summary_form"):
        submitted = st.form_submit_button("ìš”ì•½ ë³´ê³ ì„œ ìƒì„± (í˜„ì¬ ê°€ì¤‘ì¹˜ ê¸°ë°˜)")
        if submitted:
            if df_temp.empty:
                st.error("ìº í˜ì¸ ì´ë ¥ì´ ìˆëŠ” ì¸í”Œë£¨ì–¸ì„œê°€ ì—†ì–´ ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                with st.spinner(
                    "AIê°€ ì „ì²´ ë§ˆì¼€íŒ… ì„±ê³¼ë¥¼ ë¶„ì„í•˜ê³  ë³´ê³ ì„œë¥¼ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."
                ):
                    w_config = {
                        "w_er": st.session_state.w_er,
                        "w_cpr": st.session_state.w_cpr,
                        "w_reach": st.session_state.w_reach,
                        "w_cpa": st.session_state.w_cpa,
                        "w_cpm": st.session_state.w_cpm,
                    }
                    # ğŸ”¹ 3ë²ˆì—ì„œ ê³„ì‚°í•œ df_temp(ì „ëµì _ì„±ê³¼_ì ìˆ˜ í¬í•¨)ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
                    st.session_state[kpi_summary_key] = call_llm_for_kpi_summary(
                        df_temp, w_config
                    )

    if st.session_state[kpi_summary_key]:
        st.success("âœ… ë§ˆì¼€íŒ… ì „ëµ ë³´ê³ ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.markdown(st.session_state[kpi_summary_key])


# --- íƒ­ 3: í¬íŠ¸í´ë¦¬ì˜¤ ëª¨ë“ˆ ---
def portfolio_module(df_influencers: pd.DataFrame):
    st.title("ğŸ¤ Win-Win í˜‘ì—… ì œì•ˆ: ì¸í”Œë£¨ì–¸ì„œ ë°ì´í„° í¬íŠ¸í´ë¦¬ì˜¤")
    st.markdown(
        "ë‹¨ìˆœ íŒ”ë¡œì›Œ ìˆ˜ê°€ ì•„ë‹Œ, ë°ì´í„°ë¡œ ì¦ëª…ëœ **ì§„ì •í•œ ì˜í–¥ë ¥**ì„ ë³´ì—¬ì¤Œìœ¼ë¡œì¨ íˆ¬ëª…í•œ í˜‘ì—… ê´€ê³„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤."
    )
    st.markdown("---")

    influencer_names = df_influencers["ì´ë¦„"].unique().tolist()
    selected_influencer_name = st.selectbox(
        "ë°ì´í„° í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ í™•ì¸í•  ì¸í”Œë£¨ì–¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš”:", influencer_names
    )

    selected_data = df_influencers[
        df_influencers["ì´ë¦„"] == selected_influencer_name
    ].iloc[0]

    st.subheader(f"âœ¨ {selected_influencer_name} ë‹˜ì˜ í˜‘ì—… ê°€ì¹˜ ë¦¬í¬íŠ¸")
    st.markdown(
        """
> **í•µì‹¬ ë©”ì‹œì§€:** ì´ ë¦¬í¬íŠ¸ëŠ” **ì§„ì •ì„±, ì°¸ì—¬ìœ¨, ì‹¤ì œ ì „í™˜ ê¸°ì—¬ë„**ë¥¼ ê°ê´€ì ìœ¼ë¡œ ì¦ëª…í•˜ì—¬  
> í–¥í›„ ë¸Œëœë“œì™€ì˜ í˜‘ìƒë ¥ì„ ë†’ì´ëŠ” í¬íŠ¸í´ë¦¬ì˜¤ ìë£Œë¡œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
> ìš°ë¦¬ëŠ” ë‹¹ì‹ ì˜ ì§„ì •í•œ ì˜í–¥ë ¥ì— íˆ¬ìí•©ë‹ˆë‹¤.
"""
    )
    st.markdown("---")

    col1, col2, col3, col4 = st.columns(4)
    er = (
        (
            selected_data.get("í‰ê· _ì¢‹ì•„ìš”", 1000)
            + selected_data.get("í‰ê· _ëŒ“ê¸€", 100)
        )
        / selected_data["íŒ”ë¡œì›Œ ìˆ˜"]
        * 100
    )

    col1.metric("íŒ”ë¡œì›Œ ìˆ˜", f"{selected_data['íŒ”ë¡œì›Œ ìˆ˜']:,} ëª…")
    col2.metric(
        "í‰ê·  ì°¸ì—¬ìœ¨ (ER)",
        f"{er:.2f}%",
        help="íŒ”ë¡œì›Œ ëŒ€ë¹„ ì¢‹ì•„ìš”/ëŒ“ê¸€ ìˆ˜ë¡œ ê³„ì‚°ëœ í™œë™ì„± ì§€í‘œì…ë‹ˆë‹¤.",
    )
    col3.metric("ì§„ì •ì„± ì§€ìˆ˜", f"{selected_data['ì§„ì •ì„±_ì§€ìˆ˜']:.0f} ì ")
    col4.metric("ìº í˜ì¸ ì°¸ì—¬ íšŸìˆ˜", f"{selected_data['ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜']:.0f} íšŒ")

    st.markdown("---")

    st.subheader("ğŸ“Š ë¹„ì¦ˆë‹ˆìŠ¤ ê¸°ì—¬ë„ ë¶„ì„ (Campaign Performance)")
    col5, col6, col7, col8 = st.columns(4)
    if selected_data["ìº í˜ì¸_ì°¸ì—¬_íšŸìˆ˜"] > 0:
        col5.metric("í‰ê·  ì „í™˜ìœ¨ (CR)", f"{selected_data['í‰ê· _ì „í™˜ìœ¨']:.2f} %")
        col6.metric("í‰ê·  í´ë¦­ë¥  (CTR)", f"{selected_data['í‰ê· _CTR']:.2f} %")
        col7.metric("í‰ê·  CPC", f"{selected_data['í‰ê· _CPC']:.0f} ì›")
        col8.metric("í‰ê·  ê¸ì • ê°ì„± ê¸°ì—¬", f"{selected_data['í‰ê· _ê¸ì •_ê°ì •ë¹„ìœ¨']:.1f} %")

        st.markdown("---")
        st.markdown("**ì£¼ìš” ë¹„ìš© íš¨ìœ¨ ì§€í‘œ**")
        col9, col10, col11 = st.columns(3)
        col9.metric("í‰ê·  CPA", f"{selected_data['í‰ê· _CPA']:.0f} ì›")
        col10.metric("í‰ê·  CPR", f"{selected_data['í‰ê· _CPR']:.0f} ì›")
        col11.metric("í‰ê·  CPM", f"{selected_data['í‰ê· _CPM']:.0f} ì›")
    else:
        st.info("ì´ ì¸í”Œë£¨ì–¸ì„œì˜ ìº í˜ì¸ ì„±ê³¼ ë°ì´í„°ëŠ” ì•„ì§ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")

    st.subheader("ğŸ’¡ ë°ì´í„° ê¸°ë°˜ ì„±ì¥ ì§„ë‹¨ ë° Action Plan")
    growth_key = f"growth_report_{selected_data['ID']}"
    if growth_key not in st.session_state:
        st.session_state[growth_key] = None

    with st.form(key=f"growth_form_{selected_data['ID']}"):
        submitted = st.form_submit_button("AI ì„±ì¥ ì§„ë‹¨ ë¦¬í¬íŠ¸ ìƒì„±")
        if submitted:
            with st.spinner(
                f"AIê°€ {selected_influencer_name}ë‹˜ì˜ ì„±ì¥ ì ì¬ë ¥ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."
            ):
                st.session_state[growth_key] = call_llm_for_growth_analysis(
                    selected_data
                )

    if st.session_state[growth_key]:
        st.success("âœ… ì„±ì¥ ì§„ë‹¨ ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        st.markdown(st.session_state[growth_key])


# --- Streamlit ì•± ì •ì˜ (ğŸ”¹ ìˆ˜ì •ë¨) ---
# ğŸ”¹ st.set_page_configëŠ” Home.pyì—ë§Œ ìˆì–´ì•¼ í•˜ë¯€ë¡œ ì‚­ì œ
# ğŸ”¹ if __name__ == "__main__": ë° app() í˜¸ì¶œë¶€ ì‚­ì œ
# ğŸ”¹ app() í•¨ìˆ˜ì˜ ë‚´ìš©ë§Œ ë‚¨ê²¨ì„œ í˜ì´ì§€ê°€ ë°”ë¡œ ì‹¤í–‰ë˜ë„ë¡ í•¨

df_products, df_influencers = load_data()

# ğŸ”¹ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ ì‹œ í˜ì´ì§€ ì‹¤í–‰ ì¤‘ë‹¨
if df_products.empty or df_influencers.empty:
    st.error("ë°ì´í„° ë¡œë”©ì— ì‹¤íŒ¨í•˜ì—¬ í˜ì´ì§€ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# ğŸ”¹ íƒ­ì„ 2ê°œë§Œ ì‚¬ìš© (ì›ë˜ ì½”ë“œì˜ app() í•¨ìˆ˜ ë‚´ìš©)
tab1, tab2 = st.tabs(
    ["ğŸ“Š ì„±ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", "ğŸ¤ Win-Win í¬íŠ¸í´ë¦¬ì˜¤ ì œì•ˆ"]
)

df_influencers_copy = df_influencers.copy()

# ğŸ”¹ ì²« ë²ˆì§¸ íƒ­: ì„±ê³¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
with tab1:
    kpi_dashboard_module(df_influencers_copy)

# ğŸ”¹ ë‘ ë²ˆì§¸ íƒ­: í¬íŠ¸í´ë¦¬ì˜¤ ëª¨ë“ˆ
with tab2:
    portfolio_module(df_influencers_copy)